

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Workshop 10: Multi-armed bandits &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'worksheet10';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Workshop 10: Multi-armed bandits notes" href="worksheet10note.html" />
    <link rel="prev" title="Bayesian regression" href="week9.2.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to COMP90051
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="revision_progress.html">Revision Progress</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics.html">Basic Concepts</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week1.0.html">week1</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week1.1.html">Lecture 1.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week1.2.html">Lecture 2.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week1.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet2note.html">worksheet2note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week2.0.html">week2</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week2.1.html">Lecture 3.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week2.2.html">Lecture 4.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week2.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet3note.html">worksheet3note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week3.0.html">week3</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week3.1.html">Lecture 5.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week3.2.html">Lecture 6.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week3.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet4note.html">worksheet4note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week4.0.html">week4</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week4.1.html">Lecture 7.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week4.2.html">Lecture 8.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week4.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet5note.html">worksheet5note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week5.0.html">week5</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week5.1.html">Lecture 9.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week5.2.html">Lecture 10.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week5.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet6note.html">worksheet6note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week6.0.html">week6</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week6.1.html">Lecture 11.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week6.2.html">Lecture 12.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week6.3.html">Additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week7.0.html">week7</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week7.1.html">Lecture 13. Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="week7.2.html">Lecture 14. RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="week7.3.html">Additional Resource</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week8.0.html">week8</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week8.1.html">Lecture 16 Graph Convolution Networks (Deep Learning After You Drop The Camera)</a></li>
<li class="toctree-l2"><a class="reference internal" href="week8.2.html">Lecture 16. Learning with expert advice</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="week9.0.html">week9</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="week9.1.html">Stochastic Multi-Armed Bandits (MABs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="week9.2.html">Bayesian regression</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Workshop 10: Multi-armed bandits</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet10note.html">Workshop 10: Multi-armed bandits notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week10.0.html">week10</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week10.1.html">wk10 notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="week10.2.html">PGM Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="week10.3.html">Additional Notes -  More on Bayesian</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet11.html">COMP90051 Workshop 11</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week11.0.html">week11</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week11.1.html">U-PGM</a></li>
<li class="toctree-l2"><a class="reference internal" href="week11.2.html">SVM assignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="week11.3.html">Lecture 22. Inference on PGMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="asm1feedback.html">ASM2 feedback</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week12.0.html">week12</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week12.1.html">Lecture 22. Inference on PGMs Cont. &amp; Lecture 23. Gaussian Mixture Models</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="review.html">Review Notes</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="review0.html">Review 0</a></li>
<li class="toctree-l2"><a class="reference internal" href="review1.html">Review 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="review2.html">Review 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="review3.html">Review 3</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fworksheet10.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/worksheet10.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Workshop 10: Multi-armed bandits</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#media-recommendation">Media recommendation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-armed-bandits">Multi-armed bandits</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-definition">Technical definition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-details">Implementation details</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#epsilon-greedy-strategy">Epsilon-greedy strategy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#upper-confidence-bound">Upper Confidence Bound</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#offline-evaluation">Offline evaluation</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="workshop-10-multi-armed-bandits">
<h1>Workshop 10: Multi-armed bandits<a class="headerlink" href="#workshop-10-multi-armed-bandits" title="Permalink to this heading">#</a></h1>
<hr class="docutils" />
<p>In this worksheet we cover:</p>
<ul class="simple">
<li><p><span class="xref myst">multi-armed bandits</span></p></li>
<li><p><span class="xref myst">the epsilon-greedy strategy</span></p></li>
<li><p><span class="xref myst">the upper confidence bound</span></p></li>
<li><p><span class="xref myst">offline evaluation of multi-armed bandits</span></p></li>
</ul>
<p>Below we import the packages required for this worksheet.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<section id="media-recommendation">
<h2>Media recommendation<a class="headerlink" href="#media-recommendation" title="Permalink to this heading">#</a></h2>
<p>In this workshop, we consider the problem of choosing articles to recommend to users on a news website. The articles correspond to actions and clicks correspond to rewards (assumed to be {0, 1}-valued). The per round cumulative reward corresponds to the click-through-rate (CTR), which is exactly what news services want to maximise to drive user engagement and advertising revenue.</p>
<p><img alt="news-mab.png" src="attachment:news-mab.png" /></p>
<p>In this worksheet, we’ll assume information about the articles and users (“context”) is not available, which corresponds to the simplest MAB setting. However if such information were available, we could apply contextual bandits (covered briefly in lectures).</p>
</section>
<section id="multi-armed-bandits">
<h2>Multi-armed bandits<a class="headerlink" href="#multi-armed-bandits" title="Permalink to this heading">#</a></h2>
<section id="technical-definition">
<h3>Technical definition<a class="headerlink" href="#technical-definition" title="Permalink to this heading">#</a></h3>
<p>The multi-armed bandit (MAB) models an agent that must take actions (“pull arms”) so as to maximize the cumulative reward received over a finite number of rounds <span class="math notranslate nohighlight">\(T\)</span>.
In this worksheet, we index the <span class="math notranslate nohighlight">\(K\)</span> arms by <span class="math notranslate nohighlight">\(k \in \{0, \ldots, K-1\}\)</span> (starting at zero to match Python indexing).
The reward received from pulling arm <span class="math notranslate nohighlight">\(k\)</span> is assumed to follow some distribution <span class="math notranslate nohighlight">\(\mathcal{D}_k\)</span> with mean <span class="math notranslate nohighlight">\(\mu_k\)</span>, however this information is unknown to the agent.</p>
<p>The goal is to minimize the expected regret</p>
<div class="math notranslate nohighlight">
\[
R = \underbrace{T \mu^\star}_{\text{optimal strategy}} - \underbrace{\sum_{t = 1}^{T} r_t}_{\text{executed strategy}}
\]</div>
<p>where <span class="math notranslate nohighlight">\(T\)</span> is the number of rounds, <span class="math notranslate nohighlight">\(r_t\)</span> is the reward received at round <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(\mu^\star = \arg \max_k \mu_k\)</span> is the maximum mean reward.</p>
<p>Other notation:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(a_t\)</span>: index of the arm played at round <span class="math notranslate nohighlight">\(t\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(N_{t,k} = \sum_{\tau = 1}^{t} \mathbb{I}[a_\tau = k]\)</span>: number of plays for arm <span class="math notranslate nohighlight">\(k\)</span> at the end of round <span class="math notranslate nohighlight">\(t\)</span></p></li>
</ul>
</section>
<section id="implementation-details">
<h3>Implementation details<a class="headerlink" href="#implementation-details" title="Permalink to this heading">#</a></h3>
<p>We’ll be implementing epsilon-greedy MAB. It will be implemented as classes which derive from a common base class <code class="docutils literal notranslate"><span class="pre">BaseMAB</span></code> defined in the code block below.</p>
<p>There are only two public methods:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">play</span></code>: use this to pull an arm</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">update</span></code>: use this to update the internal state of the MAB based on the reward received</p></li>
</ul>
<p>Only a small amount of logic is implemented in <code class="docutils literal notranslate"><span class="pre">BaseMAB</span></code>.
It sets the number of arms; initialises an array for recording the number of pulls of each arm; and does some basic input checking.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BaseMAB</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for a multi-armed bandit (MAB)</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_arms : int</span>
<span class="sd">        Number of arms</span>
<span class="sd">    </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    n_pulls : numpy.ndarray, shape=(n_arms,)</span>
<span class="sd">        Number of pulls for each arm</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_arms</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_arms</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;`n_arms` must be an int&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_arms</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`n_arms` must be positive&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_arms</span> <span class="o">=</span> <span class="n">n_arms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_pulls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_arms</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Play a round</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        arm : int</span>
<span class="sd">            A positive integer arm id in {0, ..., n_arms - 1}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>
    
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arm</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Updates the internal state of the MAB after playing a round</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        arm : int</span>
<span class="sd">            A positive integer arm id in {0, ..., n_arms - 1}</span>
<span class="sd">        </span>
<span class="sd">        reward : float</span>
<span class="sd">            Reward received from arm</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arm</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;`arm` must be an int&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">arm</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_arms</span> <span class="ow">or</span> <span class="n">arm</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`arm` must be in the range [0, </span><span class="si">{}</span><span class="s2">]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_arms</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;`reward` must be a numeric scalar&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="epsilon-greedy-strategy">
<h2>Epsilon-greedy strategy<a class="headerlink" href="#epsilon-greedy-strategy" title="Permalink to this heading">#</a></h2>
<p>The epsilon-greedy strategy is arguably one of the simplest.
When playing an arm, the current “best” arm is selected with probability <span class="math notranslate nohighlight">\(1-\epsilon\)</span>.
Otherwise, an arm is selected uniformly at random (with probability <span class="math notranslate nohighlight">\(\epsilon\)</span>).
The current “best” arm is the one with the highest <em>estimated mean reward based</em> on the rewards seen so far (with ties broken randomly).
We estimate the mean reward of arm <span class="math notranslate nohighlight">\(k\)</span> at round <span class="math notranslate nohighlight">\(T\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Q_{t-1,k} = \begin{cases}
    \hat{\mu}_{t-1,k}, &amp; N_{t-1,k} &gt; 0 \\
    Q_0, &amp; \text{otherwise}.
\end{cases}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(N_{t-1,k} = \sum_{\tau=1}^{t-1} \mathbb{I}[a_\tau = k]\)</span> is the number of rewards observed for arm <span class="math notranslate nohighlight">\(k\)</span> at round <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(\hat{\mu}_{t-1,k} = \frac{1}{N_{t-1,k}} \sum_{\tau=1}^{t-1} r_{\tau} \mathbb{I}[a_\tau = k]\)</span> is the sample mean.
Note the special case: if no rewards have been observed for an arm we use <span class="math notranslate nohighlight">\(Q_0\)</span> (initial value) for the mean reward.</p>
<p>Thus the hyperparameters for the epsilon-greedy strategy are:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\epsilon\)</span>: the explore probability</p></li>
<li><p><span class="math notranslate nohighlight">\(Q_0\)</span>: the initial value for the estimated mean</p></li>
</ul>
<p>Let’s now implement the epsilon-greedy strategy.</p>
<p><strong>Exercise:</strong> When implementing the logic to select the “best” arm, it will be useful to have a function that computes the argmax with random tie-breaking.
In the code block below, write a function <code class="docutils literal notranslate"><span class="pre">argmax_rand</span></code> that takes a vector of values for each arm, e.g.</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x} = \begin{pmatrix}
    Q_{t-1,0} &amp; Q_{t-1,1} &amp; \cdots &amp; Q_{t-1,K-1}
\end{pmatrix}
\]</div>
<p>and returns the index <span class="math notranslate nohighlight">\(k^\star\)</span> of the largest value</p>
<div class="math notranslate nohighlight">
\[
k^\star \in \arg \max_{k \in \{0,\ldots,K-1\}} Q_{t-1,k}
\]</div>
<p>(if there’s more than one <span class="math notranslate nohighlight">\(k^\star\)</span> in this set, choose one uniformly at random).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">argmax_rand</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Argmax with ties broken uniformly at random</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : 1d numpy.ndarray</span>
<span class="sd">        Input array</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    argmax : int</span>
<span class="sd">        Integer index of the max value in x</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">max_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">max_value</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">max_indices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># If there are no arms with max UCB values, choose uniformly at random</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Randomly choose one of the indices if there are ties</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">max_indices</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In the code block below, we provide a skeleton class for the epsilon-greedy strategy.</p>
<p><strong>Exercise:</strong> Complete the implementation by writing the <code class="docutils literal notranslate"><span class="pre">play</span></code> and <code class="docutils literal notranslate"><span class="pre">update</span></code> methods.
The <code class="docutils literal notranslate"><span class="pre">argmax_rand</span></code> function defined above will come in handy when implementing the <code class="docutils literal notranslate"><span class="pre">play</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">EpsGreedy</span><span class="p">(</span><span class="n">BaseMAB</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Epsilon-Greedy multi-armed bandit</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_arms : int</span>
<span class="sd">        Number of arms</span>

<span class="sd">    epsilon : float</span>
<span class="sd">        Explore probability in interval [0, 1]</span>

<span class="sd">    Q0 : float, optional</span>
<span class="sd">        Initial value for the arms</span>
<span class="sd">    </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    n_pulls : numpy.ndarray, shape=(n_arms,)</span>
<span class="sd">        Number of pulls for each arm</span>
<span class="sd">    </span>
<span class="sd">    mean_rewards : numpy.ndarray, shape=(n_arms,)</span>
<span class="sd">        Mean reward per arm</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_arms</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">Q0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_arms</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">epsilon</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Q0</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">Q0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`epsilon` must be in the interval [0, 1]&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_arms</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q0</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">play</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">:</span>
            <span class="c1"># Exploration: Randomly select an arm</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_arms</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Exploitation: Select the arm with the highest estimated mean reward</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_rewards</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arm</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">arm</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span>
        <span class="c1"># Update the mean reward estimate for the chosen arm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_pulls</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_rewards</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_rewards</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_pulls</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">reward</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pulls</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="upper-confidence-bound">
<h2>Upper Confidence Bound<a class="headerlink" href="#upper-confidence-bound" title="Permalink to this heading">#</a></h2>
<p>The UCB strategy balances exploration and exploitation by choosing arms with not only high estimated mean reward but also high uncertainty. Specifically, it selects the arm with the highest upper confidence bound at each round, where the upper confidence bound of arm <span class="math notranslate nohighlight">\(k\)</span> is defined as
$<span class="math notranslate nohighlight">\(
Q_{t-1,k} = \begin{cases}
    \hat{\mu}_{t-1,k} + c \sqrt{\frac{\log t}{N_{t-1,k}}}, &amp; N_{t-1,k} &gt; 0 \\
    Q_0, &amp; \text{otherwise}.
\end{cases}
\)</span><span class="math notranslate nohighlight">\(
where \)</span>N_{t-1,k}<span class="math notranslate nohighlight">\( is the number of rewards observed for arm \)</span>k<span class="math notranslate nohighlight">\( at round \)</span>t<span class="math notranslate nohighlight">\(, \)</span>\hat{\mu}<em>{t-1,k}<span class="math notranslate nohighlight">\( is the sample mean, \)</span>t<span class="math notranslate nohighlight">\( is the current round, and \)</span>c<span class="math notranslate nohighlight">\( is a hyperparameter that controls the degree of exploration. The term \)</span>c \sqrt{\frac{\log t}{N</em>{t-1,k}}}$ is the exploration term, which is larger for arms that have been played fewer times or have higher variance.</p>
<p>The key hyperparameters for the UCB strategy is:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(c\)</span>: the exploration parameter</p></li>
</ul>
<p><strong>Exercise:</strong> Implement update function for UCB</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">UCB</span><span class="p">(</span><span class="n">BaseMAB</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Upper Confidence Bound (UCB) multi-armed bandit</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_arms : int</span>
<span class="sd">        Number of arms.</span>

<span class="sd">    c : float</span>
<span class="sd">        Positive real explore-exploit parameter.</span>

<span class="sd">    Q0 : float, default=np.inf</span>
<span class="sd">        Initial value for the arms.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_arms</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">Q0</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_arms</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;`c` must be a float&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">c</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`c` must be positive&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">Q0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">floating</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`Q0` must be a float&quot;</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">=</span> <span class="n">c</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Q0</span> <span class="o">=</span> <span class="n">Q0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_pulls</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_arms</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_arms</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Q_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_rewards</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_rounds</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">play</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">argmax_rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Q_values</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arm</span><span class="p">,</span> <span class="n">reward</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">arm</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span>
        
        <span class="c1"># Update the number of pulls for the chosen arm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_pulls</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="c1"># Update the mean reward estimate for the chosen arm</span>
        <span class="c1"># Calculate the new mean based on the reward received and the previous mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_rewards</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_rewards</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_pulls</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">reward</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pulls</span><span class="p">[</span><span class="n">arm</span><span class="p">]</span>
        
        <span class="c1"># Update the number of rounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_rounds</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="c1"># Update the UCB values for all arms</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_arms</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pulls</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">exploration_term</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">c</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_rounds</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_pulls</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Q_values</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_rewards</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">exploration_term</span>

        <span class="c1"># The bandit is now updated</span>
</pre></div>
</div>
</div>
</div>
<p>We’ll try out this implementation shortly, but first we need to understand how to evaluate a multi-armed bandit.</p>
</section>
<hr class="docutils" />
<section id="offline-evaluation">
<h2>Offline evaluation<a class="headerlink" href="#offline-evaluation" title="Permalink to this heading">#</a></h2>
<p>Since MABs are inherently online algorithms, it would be natural to also conduct evaluation online.
This might involve deploying a MAB algorithm in parallel with a competing algorithm and seeing which achieves the higher per round cumulative reward.
However, in practice this can be costly as a MAB algorithm begins with little knowledge about the reward structure and must inevitably yield poor rewards in earlier rounds.
In our news website example, users would be exposed to uninteresting articles merely for the sake of evaluation.</p>
<p>Fortunately, there’s an alternative option called <em>offline</em> or <em>off-policy</em> evaluation. This involves collecting a sequence of uniformly-random arm pulls and their corresponding rewards. Then any MAB of interest can be evaluated on this one historical data set—there’s no need to run the MAB online to evaluate!</p>
<p>We’ve provided a function <code class="docutils literal notranslate"><span class="pre">offlineEvaluate</span></code> below which conducts offline evaluation using a given historical data set. If you’re interested in learning more about offline evaluation, check out the reference below (not examinable):</p>
<blockquote>
<div><p>Lihong Li, Wei Chu, John Langford, Robert E. Schapire, ‘A Contextual-Bandit Approach to Personalized News Article Recommendation’, in Proceedings of the Nineteenth International Conference on World Wide Web (WWW 2010), Raleigh, NC, USA, 2010. <a class="reference external" href="https://arxiv.org/pdf/1003.0146.pdf">https://arxiv.org/pdf/1003.0146.pdf</a></p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">offlineEvaluate</span><span class="p">(</span><span class="n">mab</span><span class="p">,</span> <span class="n">arms</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">n_rounds</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Offline evaluation of a multi-armed bandit</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    mab : instance of MAB</span>
<span class="sd">        Multi-armed bandit strategy to evaluate</span>
<span class="sd">    </span>
<span class="sd">    arms : int numpy.ndarray, shape (n_events,) </span>
<span class="sd">        Sequence of randomly selected arm ids (events)</span>
<span class="sd">    </span>
<span class="sd">    rewards : float numpy.ndarray, shape (n_events,)</span>
<span class="sd">        Sequence of rewards received for each event</span>
<span class="sd">        </span>
<span class="sd">    n_rounds : int, optional</span>
<span class="sd">        Number of matching events to evaluate `mab` on.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out : 1D float array</span>
<span class="sd">        Rewards for the matching events.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mab</span><span class="p">,</span> <span class="n">BaseMAB</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;`mab` must be an instance of BaseMAB&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arms</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;`arms` must be a numpy.ndarray&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">arms</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`arms` must be a 1d array&quot;</span><span class="p">)</span>
    <span class="n">arms</span> <span class="o">=</span> <span class="n">arms</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">arms</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">mab</span><span class="o">.</span><span class="n">n_arms</span><span class="p">))</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`arms` contains values not in [0,...,n_arms-1]&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;`rewards` must be a numpy.ndarray&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rewards</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`rewards` must be a 1d array&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">arms</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`arms` and `rewards` must have the same shape&quot;</span><span class="p">)</span>
    <span class="n">rewards</span> <span class="o">=</span> <span class="n">rewards</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="c1">#     rewards = np.float64(rewards)</span>

    <span class="k">if</span> <span class="n">n_rounds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_rounds</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_rounds</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_rounds</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`n_rounds` must be non-negative&quot;</span><span class="p">)</span>    
    
    <span class="n">matched_ctr</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">matched_rewards</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">arms</span><span class="o">.</span><span class="n">size</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">n_rounds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">matched_ctr</span> <span class="o">&gt;=</span> <span class="n">n_rounds</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">arm</span> <span class="o">=</span> <span class="n">mab</span><span class="o">.</span><span class="n">play</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">arm</span> <span class="o">==</span> <span class="n">arms</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">mab</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">arm</span><span class="p">,</span> <span class="n">rewards</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">matched_ctr</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">matched_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rewards</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">matched_rewards</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s now load a historical data set.
It corresponds to a bandit problem with <span class="math notranslate nohighlight">\(K = 10\)</span> arms (news articles).
There are 10,000 uniformly-random arm pulls along with the observed rewards.
There also happens to be a 10-dimensional context vector for each arm (modelling article/user features), however we discard this as we are not doing contextual bandits.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load event log from a bandit run</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s1">&#39;dataset.txt.gz&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">arms</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">rewards</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="c1"># contexts = dataset[:,2::].astype(float).reshape(-1,10,10) (don&#39;t need contexts)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can evaluate our epsilon-greedy strategy and UCB strategy on this data set. We set <span class="math notranslate nohighlight">\(\epsilon = 0.01\)</span> for epsilon-greedy and <span class="math notranslate nohighlight">\(c=1.0\)</span> for UCB</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epsgreedy_mab</span> <span class="o">=</span> <span class="n">EpsGreedy</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span><span class="n">Q0</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">results_EpsGreedy</span> <span class="o">=</span> <span class="n">offlineEvaluate</span><span class="p">(</span><span class="n">epsgreedy_mab</span><span class="p">,</span> <span class="n">arms</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">n_rounds</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;EpsGreedy average reward&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">results_EpsGreedy</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>EpsGreedy average reward 0.01625
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ucb_mab</span> <span class="o">=</span> <span class="n">UCB</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">results_UCB</span> <span class="o">=</span> <span class="n">offlineEvaluate</span><span class="p">(</span><span class="n">ucb_mab</span><span class="p">,</span> <span class="n">arms</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">n_rounds</span><span class="o">=</span><span class="mi">800</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;UCB average reward&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">results_UCB</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>UCB average reward 0.1
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/7q/7h5d5cp54fs6_718f38b_hd00000gn/T/ipykernel_17302/1835402886.py:43: RuntimeWarning: invalid value encountered in scalar multiply
  self.mean_rewards[arm] = (self.mean_rewards[arm] * (self.n_pulls[arm] - 1) + reward) / self.n_pulls[arm]
</pre></div>
</div>
</div>
</div>
<p>Let’s plot the running average cumulative reward v.s. round</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">mab</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;EpsGreedy&#39;</span><span class="p">,</span> <span class="s1">&#39;UCB&#39;</span><span class="p">]:</span>
    <span class="n">results</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="s1">&#39;results_&#39;</span> <span class="o">+</span> <span class="n">mab</span><span class="p">)</span>
    <span class="n">t_round</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">results</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">cumsum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">/</span> <span class="n">t_round</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_round</span><span class="p">,</span> <span class="n">cumsum</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">mab</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Round&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Running average cumulative reward&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/00317cb052c1fb95fb31d5259d98eea6fe018d42c7cdbbdfe85f1465f31e93f9.png" src="_images/00317cb052c1fb95fb31d5259d98eea6fe018d42c7cdbbdfe85f1465f31e93f9.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="week9.2.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Bayesian regression</p>
      </div>
    </a>
    <a class="right-next"
       href="worksheet10note.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Workshop 10: Multi-armed bandits notes</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#media-recommendation">Media recommendation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-armed-bandits">Multi-armed bandits</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#technical-definition">Technical definition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-details">Implementation details</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#epsilon-greedy-strategy">Epsilon-greedy strategy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#upper-confidence-bound">Upper Confidence Bound</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#offline-evaluation">Offline evaluation</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
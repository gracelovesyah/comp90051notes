

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Short Answers &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'QNA';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="week1" href="week1.0.html" />
    <link rel="prev" title="Short Answer Questions" href="shortanswer.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to COMP90051
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="revision_progress.html">Revision Progress</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics.html">Basic Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="comparisons.html">Final Review Notes</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="shortanswer.html">Short Answer Questions</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Short Answers</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week1.0.html">week1</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week1.1.html">Lecture 1.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week1.2.html">Lecture 2.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week1.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet2note.html">worksheet2note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week2.0.html">week2</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week2.1.html">Lecture 3.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week2.2.html">Lecture 4.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week2.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet3note.html">worksheet3note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week3.0.html">week3</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week3.1.html">Lecture 5. Regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="week3.2.html">Lecture 6. PAC Learning Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="week3.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet4note.html">worksheet4note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week4.0.html">week4</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week4.1.html">Lecture 7. VC Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="week4.2.html">Lecture 8. Support Vector Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="week4.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet5note.html">worksheet5note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week5.0.html">week5</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week5.1.html">Lecture 9. Kernel Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="week5.2.html">Lecture 10. The Perceptron</a></li>
<li class="toctree-l2"><a class="reference internal" href="week5.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet6note.html">worksheet6note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week6.0.html">week6</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week6.1.html">Lecture 11. Neural Network Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="week6.2.html">Lecture 12.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week6.3.html">Additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week7.0.html">week7</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week7.1.html">Lecture 13. Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="week7.2.html">Lecture 14. RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="week7.3.html">Additional Resource</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week8.0.html">week8</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week8.1.html">Lecture 16 Graph Convolution Networks (Deep Learning After You Drop The Camera)</a></li>
<li class="toctree-l2"><a class="reference internal" href="week8.2.html">Lecture 16. Learning with expert advice</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week9.0.html">week9</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week9.1.html">Stochastic Multi-Armed Bandits (MABs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="week9.2.html">Bayesian regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet10note.html">Workshop 10: Multi-armed bandits notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week10.0.html">week10</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week10.1.html">Bayesian classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="week10.2.html">PGM Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="week10.3.html">Additional Notes -  More on Bayesian</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week11.0.html">week11</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week11.1.html">U-PGM</a></li>
<li class="toctree-l2"><a class="reference internal" href="week11.2.html">SVM assignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="week11.3.html">Lecture 22. Inference on PGMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="asm1feedback.html">ASM2 feedback</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week12.0.html">week12</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week12.1.html">Lecture 22. Inference on PGMs Cont. &amp; Lecture 23. Gaussian Mixture Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="week12.2.html">Lecture 24. Subject Review and Exam Info</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="review.html">Review Notes</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="review0.html">Review 0</a></li>
<li class="toctree-l2"><a class="reference internal" href="review1.html">Review 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="review2.html">Review 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="review3.html">Review 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="review4.html">Review 4</a></li>
<li class="toctree-l2"><a class="reference internal" href="review5.html">Review 5</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FQNA.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/QNA.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Short Answers</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="short-answers">
<h1>Short Answers<a class="headerlink" href="#short-answers" title="Permalink to this heading">#</a></h1>
<p><strong>Question 1: Decision Theory and Kernel Methods</strong></p>
<p>(a) Is the loss function <span class="math notranslate nohighlight">\( l(y,\hat{y}) = (\hat{y} - y)^3 \)</span> a good idea or a bad idea for supervised regression? Why?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Bad idea.</strong></p></li>
<li><p>The cubic loss function does not penalize errors symmetrically. Positive and negative errors of the same magnitude will have different losses. This can lead to undesirable biases in regression estimates.</p></li>
</ul>
</li>
</ul>
<p>(b) Explain a benefit of using the kernel trick with a polynomial kernel of degree <span class="math notranslate nohighlight">\( p = 12 \)</span> in SVM vs explicit basis expansion.</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Computational efficiency.</strong></p></li>
<li><p>Using the kernel trick, we can compute the inner product in the higher-dimensional space without explicitly computing the transformation. Explicit basis expansion for a degree 12 polynomial would involve computing a large number of polynomial features, which is computationally expensive.</p></li>
</ul>
</li>
</ul>
<p>(c) How are support vectors characterized by dual variables <span class="math notranslate nohighlight">\( \lambda_i \)</span> in the soft-margin SVM?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Non-zero values.</strong></p></li>
<li><p>In the soft-margin SVM, support vectors are data points for which the dual variable <span class="math notranslate nohighlight">\( \lambda_i \)</span> is greater than zero.</p></li>
</ul>
</li>
</ul>
<p>(d) Write an expression relating expected squared loss, bias, and variance.</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Expected squared loss = Bias^2 + Variance + Noise.</strong></p></li>
</ul>
</li>
</ul>
<p>(e) How is the objective function for soft-margin SVM a relaxation of the hard-margin SVM objective?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Inclusion of slack variables.</strong></p></li>
<li><p>Soft-margin SVM introduces slack variables to allow some misclassifications, whereas hard-margin SVM requires perfect separation of data. This makes the soft-margin SVM more flexible and applicable to non-linearly separable data.</p></li>
</ul>
</li>
</ul>
<p><strong>Question 2: General Machine Learning</strong></p>
<p>(a) Describe where within multi-armed bandit algorithms like ε-greedy, statistical estimation is performed and how these estimates are used.</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Estimation of action values.</strong></p></li>
<li><p>In ε-greedy, the value of each action (arm) is estimated based on the historical rewards. The algorithm exploits the action with the highest estimated value most of the time, and explores random actions with a probability of ε.</p></li>
</ul>
</li>
</ul>
<p>(b) Describe a problem with gradient descent during training and one approach to mitigate it.</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Vanishing or Exploding Gradients.</strong></p></li>
<li><p>Gradients can become too small (vanish) or too large (explode), making learning slow or unstable.</p></li>
<li><p><strong>Mitigation:</strong> Use techniques like gradient clipping, batch normalization, or careful initialization.</p></li>
</ul>
</li>
</ul>
<p>(c) Why are training examples weighted within the AdaBoost algorithm?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>To emphasize misclassified examples.</strong></p></li>
<li><p>AdaBoost increases the weights of misclassified examples in each iteration to focus the next weak learner on those hard-to-classify instances.</p></li>
</ul>
</li>
</ul>
<p>(d) How are generative models different from discriminative models?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Modeling approach.</strong></p></li>
<li><p>Generative models model the joint probability <span class="math notranslate nohighlight">\( P(X,Y) \)</span> and try to learn how the data is generated. Discriminative models model the conditional probability <span class="math notranslate nohighlight">\( P(Y|X) \)</span> and focus on the decision boundary between classes.</p></li>
</ul>
</li>
</ul>
<p>(e) Define the tree width of a directed graph <span class="math notranslate nohighlight">\( G \)</span> in words.</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Maximum clique size minus one.</strong></p></li>
<li><p>The tree width of a graph is the size of its largest clique (fully connected subgraph) minus one, when represented as a tree decomposition.</p></li>
</ul>
</li>
</ul>
<p>(f) Benefit of using the Gaussian mixture model (GMM) over k-means clustering.</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Flexibility in cluster shapes.</strong></p></li>
<li><p>GMM can model elliptical clusters, whereas k-means assumes spherical clusters. GMM also provides a probabilistic cluster assignment, as opposed to the hard assignment in k-means.</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p><strong>Question 1:</strong></p>
<p>(a) Why are maximum likelihood estimation, max a posteriori, and empirical risk minimization all instances of extremum estimators?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>All these methods involve <strong>optimizing</strong> (maximizing or minimizing) a particular objective function. MLE maximizes the likelihood, MAP maximizes the posterior, and ERM minimizes the empirical risk.</p></li>
</ul>
</li>
</ul>
<p>(b) Why was there a third irreducible error term in the bias-variance decomposition for supervised regression but not in parameter estimation?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>In supervised regression, the third term represents the <strong>noise</strong> inherent in the data. This error is due to the randomness in the data and cannot be reduced regardless of the model. In parameter estimation, we’re trying to estimate fixed parameters, so there’s no inherent “noise” term.</p></li>
</ul>
</li>
</ul>
<p>(c) Key difference between learning with experts and multi-armed bandit settings?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>In the <strong>learning with experts</strong> setting, the learner receives feedback on all expert predictions, regardless of which expert was chosen. In the <strong>multi-armed bandit</strong> setting, feedback is received only for the chosen action (arm).</p></li>
</ul>
</li>
</ul>
<p>(d) How do the frequentist and Bayesian approaches differ in their modeling of unknown parameters?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Frequentists</strong> view unknown parameters as fixed but unknown values. They estimate these parameters from data. <strong>Bayesians</strong> treat unknown parameters as random variables and use probability distributions to describe their uncertainty about these parameters.</p></li>
</ul>
</li>
</ul>
<p>(e) Why would a growth function <span class="math notranslate nohighlight">\( S_F(m) \)</span> of <span class="math notranslate nohighlight">\( 2^m \)</span> be bad for the PAC bound with growth function for <span class="math notranslate nohighlight">\( F \)</span>?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>A growth function of <span class="math notranslate nohighlight">\( 2^m \)</span> indicates that the hypothesis class is too complex, potentially leading to <strong>overfitting</strong>. The PAC bound would be loose or meaningless, making guarantees on generalization error weak or non-existent.</p></li>
</ul>
</li>
</ul>
<p>(f) Why doesn’t max a posteriori estimation require computation of the evidence through costly marginalization, while computing the posterior distributions does?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>In MAP, we’re finding the parameter value that <strong>maximizes</strong> the posterior. The evidence is a normalizing constant and does not affect the location of this maximum. For full posterior distributions, the evidence is needed to normalize and get a proper probability distribution.</p></li>
</ul>
</li>
</ul>
<p>(g) Is the loss function <span class="math notranslate nohighlight">\( l(y; \hat{y}) = (\hat{y} - y)^5 \)</span> a good idea or a bad idea for supervised regression?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Bad idea.</strong></p></li>
<li><p>Fifth power loss will greatly amplify the effect of outliers. It’s also not symmetric for positive and negative errors. This can introduce biases and make regression unstable.</p></li>
</ul>
</li>
</ul>
<p>(h) Strategies to change the hyperparameters of the soft-margin SVM with a RBF kernel for better performance?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>1. Adjust the regularization parameter <span class="math notranslate nohighlight">\( C \)</span></strong>: If overfitting, increase <span class="math notranslate nohighlight">\( C \)</span>; if underfitting, decrease <span class="math notranslate nohighlight">\( C \)</span>.</p></li>
<li><p><strong>2. Tune the RBF kernel parameter <span class="math notranslate nohighlight">\( \sigma \)</span></strong>: If overfitting, increase <span class="math notranslate nohighlight">\( \sigma \)</span>; if underfitting, decrease <span class="math notranslate nohighlight">\( \sigma \)</span>.</p></li>
</ul>
</li>
</ul>
<p>(i) Main drawback of Adaptive Gradient (AdaGrad) compared to RMSProp?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>AdaGrad’s learning rate can <strong>decrease too rapidly</strong> and become extremely small, causing the algorithm to converge prematurely and stop learning.</p></li>
</ul>
</li>
</ul>
<p>(j) Strategy that allows VAE to apply gradient descent through the samples of latent representation <span class="math notranslate nohighlight">\( z \)</span> to the encoder?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>VAE uses the <strong>reparameterization trick</strong>. Instead of sampling <span class="math notranslate nohighlight">\( z \)</span> directly, it samples from a standard distribution and then shifts and scales the sample using parameters from the encoder. This makes the process differentiable.</p></li>
</ul>
</li>
</ul>
<p>(k) For the graph neural network described, are the hidden states and input data located on the nodes, edges, or both?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>The hidden states <span class="math notranslate nohighlight">\( h \)</span> and input data <span class="math notranslate nohighlight">\( x \)</span> are located on the <strong>nodes</strong>. The functions <span class="math notranslate nohighlight">\( f \)</span> and <span class="math notranslate nohighlight">\( g \)</span> describe the interactions between nodes, but the states themselves reside on nodes.</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p><strong>Section A: Short Answer Questions</strong></p>
<ol class="arabic simple">
<li><p>In what respect is a recurrent neural network deep?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>RNNs are “deep” in terms of <strong>time or sequence length</strong>. They process sequences and maintain a hidden state across time steps, allowing them to capture long-range dependencies in data.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Explain how support vectors can have a margin of 1 from the decision boundary but be further than 1 unit away in Euclidean space.</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>The margin of 1 refers to the <strong>distance in the transformed feature space</strong>, not the original space. Due to the transformation (e.g., by a kernel), points may appear closer/farther in the transformed space than in the original Euclidean space.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="3">
<li><p>When is it better to use the primal program for training an SVM with a quadratic kernel?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>When the <strong>number of features (d) is less than the number of samples (n)</strong>. The complexity of the primal is related to the number of features, while the dual’s complexity is related to the number of samples.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="4">
<li><p>How are artificial neural networks a form of non-linear basis function in learning a linear model?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>ANNs transform the input using <strong>activation functions</strong> and multiple layers, effectively creating non-linear combinations of the input data. The final layer is a linear combination of these non-linear transformations, making it a linear model in a transformed, non-linear basis.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="5">
<li><p>Effect of high uncertainty over model parameters on the maximum likelihood estimate?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>High uncertainty can lead to <strong>broad likelihood functions</strong> with multiple peaks or wide regions of high likelihood, making the MLE less precise or less interpretable.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="6">
<li><p>Why is using the training likelihood for model selection problematic when choosing between models from different families?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Using training likelihood can lead to <strong>overfitting</strong>. More complex models might fit the training data better (higher likelihood) but may not generalize well to new data.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="7">
<li><p>How can momentum in an optimizer help avoid local optima or saddle points?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Momentum helps the optimizer <strong>maintain direction</strong> from previous steps. This can allow it to “roll over” small local optima or saddle points instead of getting stuck, by accumulating velocity in consistent directions.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="8">
<li><p>When is it desirable to use an estimator with high bias?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>When there’s a risk of <strong>overfitting</strong> due to limited data or high variance. A high bias estimator can regularize the model, providing simpler and potentially more generalizable solutions.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="9">
<li><p>A failure case from using complex non-linear encoder and decoder components in an autoencoder?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Complex components can <strong>overfit</strong> to the training data, allowing the autoencoder to memorize rather than learn meaningful representations. This reduces the generalization capability on new data.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="10">
<li><p>Why is conjugacy not critical when using the MAP estimator?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>For MAP, we’re interested in finding the mode (peak) of the posterior, not the full distribution. Conjugacy simplifies computations for the full posterior but isn’t strictly necessary for finding its mode.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="11">
<li><p>How can the posterior variance vary for different test points in Bayesian linear regression?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>The variance for a test point is influenced by its <strong>location relative to the training data</strong>. Points far from training data have higher uncertainty, leading to larger variances. The formula <span class="math notranslate nohighlight">\( \sigma^2 + x_*^T V_N x_* \)</span> shows that the variance depends on the test point <span class="math notranslate nohighlight">\( x_* \)</span>.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="12">
<li><p>Why is coordinate descent used in the Expectation Maximization algorithm despite the preference for gradient descent?</p></li>
</ol>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>In EM, the objective function is often <strong>decomposed</strong> into components corresponding to different variables or parameters. Coordinate descent can optimize each component (E-step or M-step) separately, making the optimization more tractable or efficient for such decompositions.</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p><strong>Question 1:</strong></p>
<p>(a) How will you change the hyperparameters of the SVM with an RBF kernel if it overfits the training set?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>1. Increase the regularization parameter <span class="math notranslate nohighlight">\( C \)</span></strong>: A larger <span class="math notranslate nohighlight">\( C \)</span> will impose more regularization, preventing overfitting.</p></li>
<li><p><strong>2. Adjust the RBF kernel parameter <span class="math notranslate nohighlight">\( \sigma \)</span> or <span class="math notranslate nohighlight">\( \gamma \)</span></strong>: Increase the width of the Gaussian function, making the decision boundary smoother.</p></li>
</ul>
</li>
</ul>
<p>(b) Main drawback of AdaGrad compared to RMSProp?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>AdaGrad’s learning rate can <strong>decrease too rapidly</strong> and become very small, causing the algorithm to converge prematurely and stop updating.</p></li>
</ul>
</li>
</ul>
<p>(c) Strategy that allows VAE to apply gradient descent through the samples of latent representation <span class="math notranslate nohighlight">\( z \)</span>?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>VAE uses the <strong>reparameterization trick</strong>. Instead of sampling <span class="math notranslate nohighlight">\( z \)</span> directly, it samples from a standard distribution and then shifts and scales the sample using parameters from the encoder, ensuring differentiability.</p></li>
</ul>
</li>
</ul>
<p>(d) Why use backpropagation through time for RNNs?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>RNNs process sequences and maintain state across time steps. <strong>Backpropagation through time (BPTT)</strong> is used to compute gradients for weight updates by unrolling the RNN over the sequence length and applying the chain rule across time steps.</p></li>
</ul>
</li>
</ul>
<p>(e) Fill in the blanks: <span class="math notranslate nohighlight">\( L \)</span> ⊂ <span class="math notranslate nohighlight">\( M \)</span> ⊂ <span class="math notranslate nohighlight">\( E \)</span>.</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>L</strong> ⊂ <strong>M</strong> ⊂ <strong>E</strong>.</p></li>
</ul>
</li>
</ul>
<p>(f) Why is there no irreducible error term in the square-loss risk for parameter estimate but it’s present in supervised regression predictor’s risk?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>The irreducible error in the regression risk arises from the inherent noise in the data (unpredictable variability). When estimating parameters, we’re trying to find the best fit to the data, but we aren’t directly modeling the data’s inherent variability. Thus, there’s no term for irreducible error in parameter estimation risk.</p></li>
</ul>
</li>
</ul>
<p>(g) Objective function optimized during GMM training?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>The <strong>log-likelihood</strong> of the data given the model parameters. Mathematically, for a GMM, the objective is:</p></li>
</ul>
</li>
</ul>
<div class="math notranslate nohighlight">
\[
\mathcal{L}(\theta) = \sum_{i=1}^{N} \log \left( \sum_{k=1}^{K} \pi_k \mathcal{N}(x_i | \mu_k, \Sigma_k) \right)
\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( \pi_k \)</span> is the mixture coefficient for component <span class="math notranslate nohighlight">\( k \)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\( \mathcal{N} \)</span> denotes the Gaussian distribution with mean <span class="math notranslate nohighlight">\( \mu_k \)</span> and covariance <span class="math notranslate nohighlight">\( \Sigma_k \)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\( N \)</span> is the number of data points, and <span class="math notranslate nohighlight">\( K \)</span> is the number of Gaussian components.</p></li>
</ul>
<p>(h) Why only one iteration of Newton-Raphson is required for linear regression?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Linear regression has a <strong>convex</strong> cost function (squared error). Newton-Raphson directly finds the point where the gradient is zero, which, in the case of convex functions like the squared error, is the global minimum. Thus, one step is sufficient to reach the optimal solution.</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p><strong>Section A: Short Answer Questions</strong></p>
<p>(a) How does the dynamic learning rate in Adagrad operate and its importance?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Adagrad adjusts the learning rate for each parameter based on the historical gradient information. Parameters with larger past gradients get smaller learning rates, and vice versa. This allows for <strong>adaptive learning</strong> and can help in situations where features have different scales or gradients.</p></li>
</ul>
</li>
</ul>
<p>(b) Key benefit of RNNs over CNNs for sequence inputs?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>RNNs inherently maintain a <strong>state across time steps</strong>, allowing them to capture long-range dependencies in sequences. This makes them especially suitable for tasks where past information is crucial for future predictions.</p></li>
</ul>
</li>
</ul>
<p>(c) How can Attention be used to process dynamic sized inputs in neural models?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Attention mechanisms allow the model to <strong>focus on different parts</strong> of the input dynamically based on the context. By weighting parts of the input differently, the model can adapt to different input lengths and prioritize relevant parts of the input.</p></li>
</ul>
</li>
</ul>
<p>(d) Can the independence assumptions of all directed probabilistic graphical models be represented by undirected ones?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>No, not all independence assumptions of directed models (Bayesian networks) can be directly represented by undirected models (Markov random fields). Some factorizations in directed models don’t have a straightforward equivalent in undirected models.</p></li>
</ul>
</li>
</ul>
<p>(e) Why use coordinate ascent in the Expectation Maximization algorithm despite the preference for gradient descent?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>In EM, the objective function is often <strong>decomposed</strong> into components corresponding to different variables or parameters. Coordinate ascent can optimize each component (E-step or M-step) separately, making the optimization more tractable or efficient for such decompositions.</p></li>
</ul>
</li>
</ul>
<p>(f) How can we tell the SVM’s primal and dual optima are always equal?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>SVM’s optimization problem satisfies the <strong>Karush-Kuhn-Tucker (KKT) conditions</strong>, which ensure strong duality. Thus, the primal and dual optima are equal when these conditions are met.</p></li>
</ul>
</li>
</ul>
<p>(g) Why are both maximum-likelihood estimators and maximum a posteriori estimators asymptotically efficient?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Both MLE and MAP estimators achieve the <strong>Cramér-Rao lower bound</strong> asymptotically, meaning their variances approach the minimum possible variance for an unbiased estimator as the sample size grows.</p></li>
</ul>
</li>
</ul>
<p>(h) Why would a growth function <span class="math notranslate nohighlight">\( S_F(m) \)</span> of <span class="math notranslate nohighlight">\( 2^m \)</span> be problematic for the PAC bound with growth function for <span class="math notranslate nohighlight">\( F \)</span>?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>A growth function of <span class="math notranslate nohighlight">\( 2^m \)</span> indicates that the hypothesis class is too complex, potentially leading to <strong>overfitting</strong>. The PAC bound would be loose or very large, making guarantees on generalization error weak or non-existent.</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p><strong>Section A: Short Answer Questions</strong></p>
<p>(a) How does the value of the learning rate, <span class="math notranslate nohighlight">\( \eta \)</span> in SGD affect the training progress?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>A <strong>high learning rate</strong> may cause oscillations and overshooting, potentially missing the minimum. A <strong>low learning rate</strong> might converge slowly or get stuck in local minima. An optimal learning rate allows steady convergence to a global or good local minimum.</p></li>
</ul>
</li>
</ul>
<p>(b) Why are vanishing gradients more concerning for RNNs than other architectures?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>RNNs process sequences and backpropagate errors through time steps. When gradients are small, they can <strong>vanish</strong> over many time steps, leading to long-range dependencies not being captured effectively and making early layers hard to train.</p></li>
</ul>
</li>
</ul>
<p>(c) How do CNNs produce translation invariant representations?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>CNNs use shared weights in their convolutional filters. This allows them to detect features regardless of their position in the input, leading to <strong>translation invariance</strong>. Pooling layers further enhance this property by reducing spatial dimensions.</p></li>
</ul>
</li>
</ul>
<p>(d) Can any undirected graphical model’s joint probability be expressed as a directed one?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Not always. Some factorizations and independence assumptions in undirected models (Markov random fields) may not have a straightforward equivalent in directed models (Bayesian networks) and vice versa.</p></li>
</ul>
</li>
</ul>
<p>(e) Advantage of using iterative gradient-based optimization when a closed form solution exists?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>While closed-form solutions are computationally efficient, gradient-based methods can be more <strong>flexible</strong>, allowing for regularization, easier integration with other components, or scalability to large datasets.</p></li>
</ul>
</li>
</ul>
<p>(f) How does the expectation maximization (EM) algorithm relate to the MLE?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>EM is used to find the <strong>maximum likelihood estimates</strong> (MLE) of parameters when the data has missing or hidden variables. It iteratively estimates the hidden variables (E-step) and then optimizes the parameters (M-step).</p></li>
</ul>
</li>
</ul>
<p>(g) How does the MAP estimate relate to the Bayesian posterior distribution over weights?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>The <strong>MAP estimate</strong> is the mode of the Bayesian posterior distribution, i.e., the value of the weights that maximizes the posterior distribution, incorporating both the likelihood of the data and the prior on the weights.</p></li>
</ul>
</li>
</ul>
<p>(h) Why do PAC bounds hold “with high probability <span class="math notranslate nohighlight">\( 1 - \delta \)</span>” and not deterministically?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>PAC bounds are probabilistic because they account for the <strong>random nature</strong> of drawing a finite sample from a distribution. The bound guarantees that the true risk is close to the empirical risk for most samples, but there’s a small probability <span class="math notranslate nohighlight">\( \delta \)</span> where this might not hold.</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p><strong>Section A: Short Answer Questions</strong></p>
<p>(a) Can training a deep neural network with tanh activation using backpropagation lead to the vanishing gradient problem? Why?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Yes, because the derivatives of the tanh function are in the range (0,1). For deep networks, multiplying these small derivatives during backpropagation can cause gradients to <strong>vanish</strong> and hinder weight updates in early layers.</p></li>
</ul>
</li>
</ul>
<p>(b) Two benefits of max pooling.</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>1. Dimensionality Reduction</strong>: Reduces spatial dimensions, leading to fewer parameters and computational savings.</p></li>
<li><p><strong>2. Translation Invariance</strong>: Provides a form of translational invariance, helping the model recognize features regardless of their exact position in the input.</p></li>
</ul>
</li>
</ul>
<p>(c) Another use of padding besides preserving spatial dimensions in convolutional layers?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>Edge Information Preservation</strong>: Padding helps in preserving information at the edges of the input by ensuring that border pixels are adequately involved in convolutions.</p></li>
</ul>
</li>
</ul>
<p>(d) Why might VC-dimension based PAC learning theory give impractical risk bounds for deep neural networks?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Deep neural networks with non-linear activations have a very <strong>high VC-dimension</strong>, which reflects their capacity to fit a large variety of functions. Using VC-dimension in PAC bounds for such models can result in very large or overly pessimistic bounds, making them less informative or useful.</p></li>
</ul>
</li>
</ul>
<p>(e) How does Thompson sampling achieve exploration in multi-armed bandit learning?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Thompson sampling samples from the posterior distribution over each arm’s reward. By occasionally sampling optimistic estimates, even for infrequently played arms, it ensures <strong>exploration</strong> of all arms over time.</p></li>
</ul>
</li>
</ul>
<p>(f) Why compute evidence for a Bayesian posterior but ignore it for MAP estimation?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>The evidence, which is the denominator in Bayes’ rule, acts as a normalizing constant to ensure the posterior is a valid probability distribution. For MAP estimation, we’re interested in the <strong>mode</strong> of the posterior, so we can ignore the evidence since it doesn’t affect the location of the mode.</p></li>
</ul>
</li>
</ul>
<p>(g) How to reduce memory footprint when training a GCN over a very large graph?</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p>Use <strong>mini-batch training</strong> with <strong>neighbor sampling</strong> or <strong>graph sampling</strong> techniques. Instead of loading the entire graph, load and process smaller subgraphs or neighborhoods iteratively.</p></li>
</ul>
</li>
</ul>
<p>(h) Two general strategies for proving that a learning algorithm can be kernelized.</p>
<ul class="simple">
<li><p><strong>Answer:</strong></p>
<ul>
<li><p><strong>1. Representer Theorem</strong>: Demonstrate that the solution to the optimization problem can be expressed as a linear combination of kernel evaluations with training data.</p></li>
<li><p><strong>2. Dual Formulation</strong>: Show that the problem’s dual formulation only involves dot products between data points, which can then be replaced by kernel functions.</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="shortanswer.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Short Answer Questions</p>
      </div>
    </a>
    <a class="right-next"
       href="week1.0.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">week1</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
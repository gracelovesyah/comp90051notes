

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Review 0 &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'review0';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Review Notes" href="review.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to COMP90051
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="revision_progress.html">Revision Progress</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics.html">Basic Concepts</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week6.0.html">week6</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week6.2.html">week6 lec2</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week7.0.html">week7</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week7.1.html">Lecture 13. Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="week7.2.html">Lecture 14. RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="week7.3.html">Additional Resource</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week8.0.html">week8</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week8.1.html">Lecture 16 Graph Convolution Networks (Deep Learning After You Drop The Camera)</a></li>
<li class="toctree-l2"><a class="reference internal" href="week8.2.html">Lecture 16. Learning with expert advice</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week9.0.html">week9</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week9.1.html">Stochastic Multi-Armed Bandits (MABs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="week9.2.html">Bayesian regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet10.html">Workshop 10: Multi-armed bandits</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet10note.html">Workshop 10: Multi-armed bandits notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week10.0.html">week10</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week10.1.html">wk10 notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="week10.2.html">PGM Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="week10.3.html">Additional Notes -  More on Bayesian</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet11.html">COMP90051 Workshop 11</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week11.0.html">week11</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week11.1.html">U-PGM</a></li>
<li class="toctree-l2"><a class="reference internal" href="week11.2.html">SVM assignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="asm1feedback.html">ASM2 feedback</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="review.html">Review Notes</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Review 0</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Freview0.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/review0.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Review 0</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mle">MLE</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-resource">Additional Resource</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian">Bayesian</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-approach">Bayesian Approach</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intuition">Intuition</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-linear-regression">Bayesian Linear Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior">1. Prior:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood">2. Likelihood:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior">3. Posterior:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation">4. Estimation:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction">5. Prediction:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages">Advantages:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-theorem">Bayes Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-regression">Bayesian Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#equation-breakdown">Equation Breakdown:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion:</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="review-0">
<h1>Review 0<a class="headerlink" href="#review-0" title="Permalink to this heading">#</a></h1>
<p>This notes is completed with assistance of <a class="reference external" href="https://chat.openai.com/c/9c7af942-d759-448c-a4ce-4e9bdeef5cbc">ChatGPT</a></p>
<section id="mle">
<h2>MLE<a class="headerlink" href="#mle" title="Permalink to this heading">#</a></h2>
<section id="additional-resource">
<h3>Additional Resource<a class="headerlink" href="#additional-resource" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=Dn6b9fCIUpM">Maximum Likelihood For the Normal Distribution, step-by-step!!!</a></p></li>
</ul>
</section>
</section>
<section id="bayesian">
<h2>Bayesian<a class="headerlink" href="#bayesian" title="Permalink to this heading">#</a></h2>
<p>In the realm of statistics and machine learning, Bayesian inference is a method of statistical inference where Bayes’ theorem is used to update the probability estimate for a hypothesis as more evidence becomes available. This is especially useful in parameter estimation.</p>
<p>Let’s take a simple example: Estimating the bias of a coin.</p>
<section id="setup">
<h3>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h3>
<p>Imagine you have a coin, and you want to estimate the probability <span class="math notranslate nohighlight">\( \theta \)</span> of it landing heads. In a frequentist setting, you might flip it many times and compute the fraction of times it lands heads. In a Bayesian setting, you start with a prior belief about <span class="math notranslate nohighlight">\( \theta \)</span> and update this belief with observed data.</p>
</section>
<section id="bayesian-approach">
<h3>Bayesian Approach<a class="headerlink" href="#bayesian-approach" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Prior</strong>: Start with a prior distribution over <span class="math notranslate nohighlight">\( \theta \)</span>. A common choice for the bias of a coin is the Beta distribution, which is parameterized by two positive shape parameters, <span class="math notranslate nohighlight">\( \alpha \)</span> and <span class="math notranslate nohighlight">\( \beta \)</span>. If you have no strong belief about the coin’s bias, you might choose <span class="math notranslate nohighlight">\( \alpha = \beta = 1 \)</span>, which is equivalent to a uniform distribution over [0, 1].</p></li>
<li><p><strong>Likelihood</strong>: This is the probability of observing the data given a particular value of <span class="math notranslate nohighlight">\( \theta \)</span>. If you flip the coin <span class="math notranslate nohighlight">\( n \)</span> times and observe <span class="math notranslate nohighlight">\( h \)</span> heads, the likelihood is given by the binomial distribution:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[ P(data|\theta) = \binom{n}{h} \theta^h (1-\theta)^{n-h} \]</div>
<ol class="arabic simple" start="3">
<li><p><strong>Posterior</strong>: Using Bayes’ theorem, the posterior distribution for <span class="math notranslate nohighlight">\( \theta \)</span> after observing the data is:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[ P(\theta|data) = \frac{P(data|\theta) \times P(\theta)}{P(data)} \]</div>
<div class="math notranslate nohighlight">
\[
Posterior == \frac{Likelihood \cdot Prior}{Evidence}
\]</div>
<p>Given the conjugacy between the Beta prior and the Binomial likelihood, the posterior is also a Beta distribution but with updated parameters: <span class="math notranslate nohighlight">\( \alpha' = \alpha + h \)</span> and <span class="math notranslate nohighlight">\( \beta' = \beta + n - h \)</span>.</p>
<ol class="arabic simple" start="4">
<li><p><strong>Estimation</strong>: There are different ways to estimate <span class="math notranslate nohighlight">\( \theta \)</span> from the posterior distribution. A common choice is to use the mean of the posterior, which for a Beta distribution is:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[ \hat{\theta} = \frac{\alpha'}{\alpha' + \beta'} \]</div>
<hr class="docutils" />
<p>The posterior distribution <span class="math notranslate nohighlight">\(P(\theta | \text{data})\)</span> represents the updated probability distribution of parameter(s) <span class="math notranslate nohighlight">\(\theta\)</span> after incorporating observed data, providing estimates, quantifying uncertainty, and allowing the integration of prior knowledge in Bayesian analysis.</p>
</section>
<section id="intuition">
<h3>Intuition<a class="headerlink" href="#intuition" title="Permalink to this heading">#</a></h3>
<p>Let’s say you start with a completely uniform prior (no knowledge about the coin’s bias). After flipping the coin 10 times, you observe 7 heads. Your belief (posterior distribution) about the coin’s bias will shift toward 0.7, but it will also consider your initial uncertainty. The more data (coin flips) you observe, the more your belief will be influenced by the observed data relative to the prior.</p>
<p>In Bayesian parameter estimation, rather than obtaining a single “best estimate” value as in frequentist statistics, you obtain a distribution over the possible parameter values that reflects both the data and the prior beliefs.</p>
<hr class="docutils" />
<p>The posterior distribution <span class="math notranslate nohighlight">\(P(\theta | \text{data})\)</span> represents the updated probability distribution of parameter(s) <span class="math notranslate nohighlight">\(\theta\)</span> after incorporating observed data, providing estimates, quantifying uncertainty, and allowing the integration of prior knowledge in Bayesian analysis.</p>
</section>
</section>
<section id="bayesian-linear-regression">
<h2>Bayesian Linear Regression<a class="headerlink" href="#bayesian-linear-regression" title="Permalink to this heading">#</a></h2>
<p>Suppose you have data <span class="math notranslate nohighlight">\( \mathbf{X} \)</span> and <span class="math notranslate nohighlight">\( \mathbf{y} \)</span>, and you’re trying to model the relationship between them using linear regression:</p>
<div class="math notranslate nohighlight">
\[ \mathbf{y} = \mathbf{X} \beta + \epsilon \]</div>
<p>where <span class="math notranslate nohighlight">\( \epsilon \sim N(0, \sigma^2I) \)</span> represents the errors.</p>
<section id="prior">
<h3>1. Prior:<a class="headerlink" href="#prior" title="Permalink to this heading">#</a></h3>
<p>In the Bayesian approach, you start by defining prior distributions on the parameters you wish to estimate. For simplicity, let’s consider priors on the regression coefficients <span class="math notranslate nohighlight">\( \beta \)</span>:</p>
<div class="math notranslate nohighlight">
\[ \beta \sim N(0, \lambda^2I) \]</div>
<p>This is a normal prior with mean 0 and variance <span class="math notranslate nohighlight">\( \lambda^2 \)</span>. The choice of prior can be changed based on domain knowledge or other considerations.</p>
</section>
<section id="likelihood">
<h3>2. Likelihood:<a class="headerlink" href="#likelihood" title="Permalink to this heading">#</a></h3>
<p>Given the linear regression model, the likelihood for the observed data is:</p>
<div class="math notranslate nohighlight">
\[ P(\mathbf{y} | \mathbf{X}, \beta) \propto e^{-\frac{1}{2\sigma^2}(\mathbf{y} - \mathbf{X}\beta)^T(\mathbf{y} - \mathbf{X}\beta)} \]</div>
</section>
<section id="posterior">
<h3>3. Posterior:<a class="headerlink" href="#posterior" title="Permalink to this heading">#</a></h3>
<p>Using Bayes’ theorem, the posterior distribution for <span class="math notranslate nohighlight">\( \beta \)</span> after observing the data is:</p>
<div class="math notranslate nohighlight">
\[ P(\beta | \mathbf{y}, \mathbf{X}) \propto P(\mathbf{y} | \mathbf{X}, \beta) \times P(\beta) \]</div>
<p>Combining the likelihood and prior, the posterior becomes a multivariate normal distribution in the case of Gaussian priors and likelihoods.</p>
</section>
<section id="estimation">
<h3>4. Estimation:<a class="headerlink" href="#estimation" title="Permalink to this heading">#</a></h3>
<p>The goal in Bayesian regression isn’t just to find point estimates of the parameters (like the MLE in frequentist regression), but rather to describe the entire posterior distribution. This provides insight into the uncertainty associated with parameter estimates.</p>
<p>In practice, due to the high-dimensional nature of the posterior distribution, especially in regression with many predictors, sampling methods like Markov Chain Monte Carlo (MCMC) or Variational Inference might be used to approximate this distribution.</p>
</section>
<section id="prediction">
<h3>5. Prediction:<a class="headerlink" href="#prediction" title="Permalink to this heading">#</a></h3>
<p>To make predictions for new data <span class="math notranslate nohighlight">\( \mathbf{X_{new}} \)</span> using the Bayesian model, you would consider the entire posterior distribution of <span class="math notranslate nohighlight">\( \beta \)</span>. This results in a distribution over possible predicted values rather than a single predicted value.</p>
</section>
<section id="advantages">
<h3>Advantages:<a class="headerlink" href="#advantages" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Incorporate Prior Knowledge</strong>: If you have prior knowledge or beliefs about the relationship being modeled, Bayesian methods allow you to incorporate that knowledge.</p></li>
<li><p><strong>Parameter Uncertainty</strong>: Bayesian methods provide a full distribution over the parameters, offering a more comprehensive view of parameter uncertainty.</p></li>
<li><p><strong>Regularization Effect</strong>: The inclusion of priors can have a regularization effect similar to Ridge or Lasso regression, preventing overfitting.</p></li>
</ol>
<p>In summary, Bayesian regression provides a more comprehensive view of uncertainty, allowing for prior beliefs to be incorporated into the model and yielding full posterior distributions of model parameters instead of just point estimates.</p>
</section>
</section>
<section id="bayes-theorem">
<h2>Bayes Theorem<a class="headerlink" href="#bayes-theorem" title="Permalink to this heading">#</a></h2>
<p>Here’s a step-by-step derivation of Bayes’ theorem:</p>
<p><strong>Step 1: Define Conditional Probability</strong></p>
<ul class="simple">
<li><p>We start with the definition of conditional probability, denoted as <span class="math notranslate nohighlight">\(P(A | B)\)</span>, which represents the probability of event <span class="math notranslate nohighlight">\(A\)</span> occurring given that event <span class="math notranslate nohighlight">\(B\)</span> has occurred. Mathematically, this is defined as:
$<span class="math notranslate nohighlight">\(P(A | B) = \frac{P(A \cap B)}{P(B)}\)</span><span class="math notranslate nohighlight">\(
Here, \)</span>P(A \cap B)<span class="math notranslate nohighlight">\( represents the probability of both events \)</span>A<span class="math notranslate nohighlight">\( and \)</span>B$ occurring together.</p></li>
</ul>
<p><strong>Step 2: Rearrange the Conditional Probability Formula</strong></p>
<ul class="simple">
<li><p>We can rearrange the above formula to solve for <span class="math notranslate nohighlight">\(P(A \cap B)\)</span>:
$<span class="math notranslate nohighlight">\(P(A \cap B) = P(A | B) \cdot P(B)\)</span>$</p></li>
</ul>
<p><strong>Step 3: Apply the Symmetry of Conditional Probability</strong></p>
<ul class="simple">
<li><p>We know that <span class="math notranslate nohighlight">\(P(A \cap B) = P(B \cap A)\)</span>. This is because the order in which we consider events does not affect the probability of their intersection.</p></li>
</ul>
<p><strong>Step 4: Express <span class="math notranslate nohighlight">\(P(B \cap A)\)</span> in Terms of Conditional Probability</strong></p>
<ul class="simple">
<li><p>We can use the definition of conditional probability to express <span class="math notranslate nohighlight">\(P(B \cap A)\)</span> as follows:
$<span class="math notranslate nohighlight">\(P(B \cap A) = P(B | A) \cdot P(A)\)</span>$</p></li>
</ul>
<p><strong>Step 5: Equate the Expressions for <span class="math notranslate nohighlight">\(P(A \cap B)\)</span></strong></p>
<ul class="simple">
<li><p>Equate the expressions for <span class="math notranslate nohighlight">\(P(A \cap B)\)</span> obtained in Step 2 and Step 4:
$<span class="math notranslate nohighlight">\(P(A | B) \cdot P(B) = P(B | A) \cdot P(A)\)</span>$</p></li>
</ul>
<p><strong>Step 6: Solve for Bayes’ Theorem</strong></p>
<ul class="simple">
<li><p>Finally, we can rearrange the equation from Step 5 to obtain Bayes’ theorem in its general form:
$<span class="math notranslate nohighlight">\(P(A | B) = \frac{P(B | A) \cdot P(A)}{P(B)}\)</span>$</p></li>
</ul>
<p>This is the general form of Bayes’ theorem. It provides a way to update the probability of an event <span class="math notranslate nohighlight">\(A\)</span> in light of new evidence or information provided by event <span class="math notranslate nohighlight">\(B\)</span>. The theorem is widely used in statistics, machine learning, and various fields for tasks such as probabilistic inference, Bayesian statistics, and Bayesian reasoning.</p>
</section>
<hr class="docutils" />
<section id="bayesian-regression">
<h2>Bayesian Regression<a class="headerlink" href="#bayesian-regression" title="Permalink to this heading">#</a></h2>
<section id="equation-breakdown">
<h3>Equation Breakdown:<a class="headerlink" href="#equation-breakdown" title="Permalink to this heading">#</a></h3>
<div class="math notranslate nohighlight">
\[ p(y^*|x^*, x, y) = \int p(y^*|x^*, w) \times p(w|x, y) \, dw \]</div>
<p>Here:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( y^* \)</span> is a new output (or set of outputs) that you’re trying to predict.</p></li>
<li><p><span class="math notranslate nohighlight">\( x^* \)</span> is the new input (or set of inputs) corresponding to <span class="math notranslate nohighlight">\( y^* \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( x \)</span> and <span class="math notranslate nohighlight">\( y \)</span> are the observed inputs and outputs (your data).</p></li>
<li><p><span class="math notranslate nohighlight">\( w \)</span> represents the parameters of the model.</p></li>
<li><p><span class="math notranslate nohighlight">\( p(y^*|x^*, w) \)</span> is the likelihood of observing <span class="math notranslate nohighlight">\( y^* \)</span> given the new input <span class="math notranslate nohighlight">\( x^* \)</span> and some fixed parameters <span class="math notranslate nohighlight">\( w \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( p(w|x, y) \)</span> is the posterior distribution of the parameters <span class="math notranslate nohighlight">\( w \)</span> given the observed data <span class="math notranslate nohighlight">\( x \)</span> and <span class="math notranslate nohighlight">\( y \)</span>.</p></li>
</ul>
</section>
<section id="interpretation">
<h3>Interpretation:<a class="headerlink" href="#interpretation" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Posterior Predictive Distribution <span class="math notranslate nohighlight">\( p(y^*|x^*, x, y) \)</span></strong>:</p>
<ul class="simple">
<li><p>This is the distribution of the new outputs <span class="math notranslate nohighlight">\( y^* \)</span> given new inputs <span class="math notranslate nohighlight">\( x^* \)</span> and the observed data <span class="math notranslate nohighlight">\( x, y \)</span>.</p></li>
<li><p>It integrates over all possible parameter values <span class="math notranslate nohighlight">\( w \)</span> weighted by their probability given the observed data.</p></li>
</ul>
</li>
<li><p><strong>Likelihood <span class="math notranslate nohighlight">\( p(y^*|x^*, w) \)</span></strong>:</p>
<ul class="simple">
<li><p>This term describes how likely the new outputs <span class="math notranslate nohighlight">\( y^* \)</span> are for given inputs <span class="math notranslate nohighlight">\( x^* \)</span> if the model parameters were fixed at <span class="math notranslate nohighlight">\( w \)</span>.</p></li>
</ul>
</li>
<li><p><strong>Posterior <span class="math notranslate nohighlight">\( p(w|x, y) \)</span></strong>:</p>
<ul class="simple">
<li><p>This term represents the updated beliefs about the model parameters <span class="math notranslate nohighlight">\( w \)</span> after observing the data <span class="math notranslate nohighlight">\( x \)</span> and <span class="math notranslate nohighlight">\( y \)</span>.</p></li>
</ul>
</li>
<li><p><strong>Integration over <span class="math notranslate nohighlight">\( w \)</span></strong>:</p>
<ul class="simple">
<li><p>The integration accounts for the uncertainty in the model parameters. Instead of just making a prediction based on a single “best” estimate of <span class="math notranslate nohighlight">\( w \)</span>, you’re averaging predictions across all possible values of <span class="math notranslate nohighlight">\( w \)</span>, weighted by their posterior probability.</p></li>
<li><p>This results in a more robust prediction that accounts for parameter uncertainty.</p></li>
</ul>
</li>
</ol>
</section>
<section id="conclusion">
<h3>Conclusion:<a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h3>
<p>The equation is essentially saying: “To predict a new output <span class="math notranslate nohighlight">\( y^* \)</span> given new inputs <span class="math notranslate nohighlight">\( x^* \)</span> and the observed data <span class="math notranslate nohighlight">\( x, y \)</span>, consider all possible parameter values <span class="math notranslate nohighlight">\( w \)</span>, weigh the predictions for each parameter value by the probability of that parameter value given the data, and then sum (integrate) these weighted predictions.”</p>
<p>This approach embodies a key tenet of Bayesian reasoning: consider all possibilities and weigh them by their probabilities. This leads to predictions that account for both the uncertainty in the model parameters and the inherent variability in the data-generating process.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="review.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Review Notes</p>
      </div>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mle">MLE</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-resource">Additional Resource</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian">Bayesian</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-approach">Bayesian Approach</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intuition">Intuition</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-linear-regression">Bayesian Linear Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior">1. Prior:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood">2. Likelihood:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior">3. Posterior:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation">4. Estimation:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction">5. Prediction:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advantages">Advantages:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-theorem">Bayes Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-regression">Bayesian Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#equation-breakdown">Equation Breakdown:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretation">Interpretation:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion:</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
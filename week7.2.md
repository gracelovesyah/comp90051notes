# Lecture 14. 

This notes is completed with assistance of [ChatGPT](https://chat.openai.com/c/e37f2c38-a8bd-49b6-ad32-65aadbb10dda)

## Random Notes
- RNN: memory, issues when input data of different length
- Vanilla Neural Networks: A vanilla neural network, often simply called a feedforward neural network, is the most basic type of artificial neural network architecture. When dealing with sequential input, traditional fixed-size input neural networks like vanilla feedforward networks are not the most suitable. Sequential data has inherent temporal dependencies, meaning the order of the data points matters. Here's how we can handle sequential input in the context of deep neural networks (DNNs):





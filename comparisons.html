

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Final Review Notes &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'comparisons';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="week1" href="week1.0.html" />
    <link rel="prev" title="Resources" href="resources.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to COMP90051
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="revision_progress.html">Revision Progress</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics.html">Basic Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Resources</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Final Review Notes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week1.0.html">week1</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week1.1.html">Lecture 1.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week1.2.html">Lecture 2.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week1.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet2note.html">worksheet2note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week2.0.html">week2</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week2.1.html">Lecture 3.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week2.2.html">Lecture 4.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week2.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet3note.html">worksheet3note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week3.0.html">week3</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week3.1.html">Lecture 5. Regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="week3.2.html">Lecture 6. PAC Learning Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="week3.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet4note.html">worksheet4note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week4.0.html">week4</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week4.1.html">Lecture 7. VC Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="week4.2.html">Lecture 8. Support Vector Machines</a></li>
<li class="toctree-l2"><a class="reference internal" href="week4.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet5note.html">worksheet5note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week5.0.html">week5</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week5.1.html">Lecture 9. Kernel Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="week5.2.html">Lecture 10. The Perceptron</a></li>
<li class="toctree-l2"><a class="reference internal" href="week5.3.html">Additional notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet6note.html">worksheet6note</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week6.0.html">week6</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week6.1.html">Lecture 11. Neural Network Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="week6.2.html">Lecture 12.</a></li>
<li class="toctree-l2"><a class="reference internal" href="week6.3.html">Additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week7.0.html">week7</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week7.1.html">Lecture 13. Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="week7.2.html">Lecture 14. RNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="week7.3.html">Additional Resource</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week8.0.html">week8</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week8.1.html">Lecture 16 Graph Convolution Networks (Deep Learning After You Drop The Camera)</a></li>
<li class="toctree-l2"><a class="reference internal" href="week8.2.html">Lecture 16. Learning with expert advice</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week9.0.html">week9</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week9.1.html">Stochastic Multi-Armed Bandits (MABs)</a></li>
<li class="toctree-l2"><a class="reference internal" href="week9.2.html">Bayesian regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="worksheet10note.html">Workshop 10: Multi-armed bandits notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week10.0.html">week10</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week10.1.html">Bayesian classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="week10.2.html">PGM Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="week10.3.html">Additional Notes -  More on Bayesian</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week11.0.html">week11</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week11.1.html">U-PGM</a></li>
<li class="toctree-l2"><a class="reference internal" href="week11.2.html">SVM assignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="week11.3.html">Lecture 22. Inference on PGMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="asm1feedback.html">ASM2 feedback</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week12.0.html">week12</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week12.1.html">Lecture 22. Inference on PGMs Cont. &amp; Lecture 23. Gaussian Mixture Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="week12.2.html">Lecture 24. Subject Review and Exam Info</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="review.html">Review Notes</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="review0.html">Review 0</a></li>
<li class="toctree-l2"><a class="reference internal" href="review1.html">Review 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="review2.html">Review 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="review3.html">Review 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="review4.html">Review 4</a></li>
<li class="toctree-l2"><a class="reference internal" href="review5.html">Review 5</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fcomparisons.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/comparisons.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Final Review Notes</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-and-var">Bias and Var</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-importance-reasons-and-approaches">Regularization: Importance, Reasons, and Approaches</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting-and-underfitting">Overfitting and Underfitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pac-and-vc">PAC and VC</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pac">PAC</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vc">VC</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vc-and-pac">VC and PAC</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linearity">Linearity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mle">MLE</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-and-ols-blue">MLE and OLS (BLUE)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-estimation-example">MLE estimation example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-and-optimisation">MLE and optimisation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-algorithms">Optimization algorithms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent-algorithm"><strong>Gradient Descent Algorithm</strong>:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-gradient-descent-sgd"><strong>Stochastic Gradient Descent (SGD)</strong>:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nn">NN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropogation">Backpropogation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rnn-and-bptt">RNN and BPTT</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimisation-algorithm-nn-vs-other">Optimisation Algorithm (NN vs Other)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-and-rnn">LSTM and RNN</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#svm">SVM</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lamda-and-c">lamda and C</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kernel-proof">Kernel Proof</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-with-mermer-s">Example with Mermer’s</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sum">sum</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#product">product</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#exp">exp</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-proof-solutions">general proof solutions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unconventional-data">Unconventional Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#popular-kernels">Popular Kernels</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cnn">CNN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cnn-and-vi">CNN and VI</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-vs-discriminative">Generative vs Discriminative</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoder">Autoencoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#map">MAP</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#difference-between-map-and-full-bayesian-inference"><strong>Difference between MAP and Full Bayesian Inference</strong>:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#map-and-ridge-regression-solution">MAP and ridge regression solution.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#map-and-mle">MAP and MLE</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#at-which-case-is-map-same-as-mle">At which case is MAP same as MLE</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pgm">PGM</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="final-review-notes">
<h1>Final Review Notes<a class="headerlink" href="#final-review-notes" title="Permalink to this heading">#</a></h1>
<section id="bias-and-var">
<h2>Bias and Var<a class="headerlink" href="#bias-and-var" title="Permalink to this heading">#</a></h2>
<p>The expected test error (or risk) for an input <span class="math notranslate nohighlight">\( x \)</span> can be decomposed as:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}\left[ \left( Y - \hat{f}(x) \right)^2 \right] = \text{Bias}^2(\hat{f}(x)) + \text{Var}(\hat{f}(x)) + \text{Irreducible Error}
\]</div>
<p>Where:</p>
<ol class="arabic simple">
<li><p><strong>Bias</strong> is the difference between the expected prediction of our model and the true values. It measures how much, on average, our predictions differ from the true values.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\text{Bias}(\hat{f}(x)) = \mathbb{E}[\hat{f}(x)] - f(x)
\]</div>
<ol class="arabic simple" start="2">
<li><p><strong>Variance</strong> measures the variability of model predictions for different training sets. It indicates how much the predictions for a given point vary between different realizations of the model.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\text{Var}(\hat{f}(x)) = \mathbb{E}\left[ \left( \hat{f}(x) - \mathbb{E}[\hat{f}(x)] \right)^2 \right]
\]</div>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/bias.png"><img alt="bias" class="bg-primary mb-1 align-center" src="_images/bias.png" style="width: 800px;" /></a>
</section>
<section id="regularization-importance-reasons-and-approaches">
<h2>Regularization: Importance, Reasons, and Approaches<a class="headerlink" href="#regularization-importance-reasons-and-approaches" title="Permalink to this heading">#</a></h2>
<p><strong>Reasons for Regularization</strong>:</p>
<ol class="arabic simple">
<li><p>Presence of irrelevant features and collinearity in the dataset.</p></li>
<li><p>Can lead to:</p>
<ul class="simple">
<li><p>Ill-posed optimization problems, especially in linear regression.</p></li>
<li><p>Broken interpretability due to inflated or unreliable coefficients.</p></li>
</ul>
</li>
</ol>
<p><strong>Importance</strong>:</p>
<ul class="simple">
<li><p>Regularization introduces constraints to prevent overfitting.</p></li>
<li><p>Ensures stability in predictions and maintains model simplicity.</p></li>
<li><p>Helps in feature selection, especially with L1 regularization.</p></li>
</ul>
<p><strong>Approaches</strong>:</p>
<ol class="arabic simple">
<li><p><strong>L2 Regularization (Ridge Regression)</strong>:</p>
<ul class="simple">
<li><p>Aims to re-condition the optimization problem.</p></li>
<li><p>Equivalently, it’s the Maximum a Posteriori (MAP) estimation in a Bayesian context with a Gaussian prior on weights.</p></li>
</ul>
</li>
<li><p><strong>L1 Regularization (The Lasso)</strong>:</p>
<ul class="simple">
<li><p>Induces sparsity in the model, effectively leading to feature selection.</p></li>
<li><p>Especially favored in situations with high-dimensional features but limited data points.</p></li>
</ul>
</li>
</ol>
<p><strong>Multiple Intuitions</strong>:</p>
<ul class="simple">
<li><p>Regularization can be understood through various lenses, including algebraic and geometric interpretations.</p></li>
</ul>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model/Technique</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Regularization Effect</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Linear Regression</strong></p></td>
<td><p>Linear</p></td>
<td><p>Simple linear relationship between predictors and response.</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Ridge Regression</strong></p></td>
<td><p>Linear</p></td>
<td><p>Linear regression with <span class="math notranslate nohighlight">\(L2\)</span> penalty on coefficients.</p></td>
<td><p>Shrinks coefficients toward zero but doesn’t set them exactly to zero.</p></td>
</tr>
<tr class="row-even"><td><p><strong>The Lasso</strong></p></td>
<td><p>Linear</p></td>
<td><p>Linear regression with <span class="math notranslate nohighlight">\(L1\)</span> penalty on coefficients.</p></td>
<td><p>Can drive some coefficients to zero, effectively excluding them from the model (feature selection).</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Bayesian MAP (Gaussian Prior)</strong></p></td>
<td><p>Linear</p></td>
<td><p>Bayesian interpretation of Ridge Regression.</p></td>
<td><p>Similar effect as Ridge Regression with coefficients being shrunk toward zero.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Bayesian MAP (Laplace Prior)</strong></p></td>
<td><p>Linear</p></td>
<td><p>Bayesian interpretation of Lasso.</p></td>
<td><p>Similar effect as Lasso, potentially setting some coefficients to zero.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Non-linear Regression</strong></p></td>
<td><p>Non-linear</p></td>
<td><p>Models capturing complex, non-linear relationships between predictors and response.</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p><strong>Neural Networks (with <span class="math notranslate nohighlight">\(L1\)</span> or <span class="math notranslate nohighlight">\(L2\)</span> regularization)</strong></p></td>
<td><p>Non-linear</p></td>
<td><p>Networks of perceptrons capturing complex patterns in data.</p></td>
<td><p><span class="math notranslate nohighlight">\(L1\)</span> can make some weights zero (feature selection). <span class="math notranslate nohighlight">\(L2\)</span> shrinks weights toward zero but doesn’t usually set them to zero.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Decision Trees (with pruning)</strong></p></td>
<td><p>Non-linear</p></td>
<td><p>Hierarchical model that splits data based on feature thresholds.</p></td>
<td><p>Pruning reduces the depth/complexity of the tree, avoiding overly specific splits.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Kernel Methods (e.g., SVM with regularization)</strong></p></td>
<td><p>Non-linear</p></td>
<td><p>Models that transform data into higher-dimensional spaces for linear separation.</p></td>
<td><p>Choice of kernel and regularization parameter can control model flexibility and overfitting.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="overfitting-and-underfitting">
<h2>Overfitting and Underfitting<a class="headerlink" href="#overfitting-and-underfitting" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head"><p>Overfitting Techniques</p></th>
<th class="head"><p>Underfitting Techniques</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Linear Regression</strong></p></td>
<td><p>- Ridge or Lasso regularization<br> - Feature selection<br> - Avoid high-degree polynomials</p></td>
<td><p>- Polynomial features<br> - Reduce regularization strength</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Decision Trees</strong></p></td>
<td><p>- Tree pruning<br> - Random Forest or ensemble methods</p></td>
<td><p>- Increase tree depth<br> - Fewer constraints (e.g., min samples per split)</p></td>
</tr>
<tr class="row-even"><td><p><strong>SVM</strong></p></td>
<td><p>- Increase regularization<br> - Simpler kernel (e.g., linear)</p></td>
<td><p>- Decrease regularization<br> - Complex kernel (e.g., RBF)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Neural Networks</strong></p></td>
<td><p>- Dropout<br> - Weight regularization<br> - Smaller network<br> - Data augmentation<br> - Early stopping</p></td>
<td><p>- Larger network<br> - More epochs<br> - Complex architectures</p></td>
</tr>
<tr class="row-even"><td><p><strong>k-NN</strong></p></td>
<td><p>- Increase <span class="math notranslate nohighlight">\( k \)</span><br> - Distance weighting</p></td>
<td><p>- Decrease <span class="math notranslate nohighlight">\( k \)</span></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Logistic Regression</strong></p></td>
<td><p>- L1 or L2 regularization<br> - Feature selection</p></td>
<td><p>- Polynomial features<br> - Reduce regularization strength</p></td>
</tr>
<tr class="row-even"><td><p><strong>CNN</strong></p></td>
<td><p>- Dropout<br> - Weight regularization<br> - Use fewer layers/filters<br> - Data augmentation<br> - Early stopping</p></td>
<td><p>- Deeper architecture<br> - More filters<br> - Advanced architectures (e.g., ResNet)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>RNN</strong></p></td>
<td><p>- Dropout<br> - Weight regularization<br> - Use fewer layers/units<br> - Gradient clipping</p></td>
<td><p>- More layers/units<br> - Advanced architectures (e.g., LSTM, GRU)</p></td>
</tr>
<tr class="row-even"><td><p><strong>LSTM</strong></p></td>
<td><p>- Dropout<br> - Weight regularization<br> - Use fewer layers/units<br> - Gradient clipping<br> - Peephole connections</p></td>
<td><p>- More layers/units<br> - Stacking multiple LSTM layers</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Naive Bayes</strong></p></td>
<td><p>- Use smoothing (e.g., Laplace)</p></td>
<td><p>- Feature engineering</p></td>
</tr>
<tr class="row-even"><td><p><strong>Boosted Trees (e.g., XGBoost, AdaBoost)</strong></p></td>
<td><p>- Regularization<br> - Shrinkage (learning rate)<br> - Early stopping<br> - Limit tree depth</p></td>
<td><p>- Increase tree depth<br> - Increase number of rounds/boosting iterations</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Random Forest</strong></p></td>
<td><p>- Limit tree depth<br> - Use fewer trees<br> - Random subspace method</p></td>
<td><p>- Increase number of trees<br> - More features per split</p></td>
</tr>
<tr class="row-even"><td><p><strong>Gradient Boosting Machines (GBM)</strong></p></td>
<td><p>- Regularization<br> - Shrinkage (learning rate)<br> - Early stopping<br> - Subsampling data</p></td>
<td><p>- Increase depth/number of trees<br> - Decrease regularization</p></td>
</tr>
<tr class="row-odd"><td><p><strong>GRU (Gated Recurrent Unit)</strong></p></td>
<td><p>- Dropout<br> - Weight regularization<br> - Gradient clipping</p></td>
<td><p>- More layers/units<br> - Stacking multiple GRU layers</p></td>
</tr>
<tr class="row-even"><td><p><strong>Transformer (e.g., BERT, GPT)</strong></p></td>
<td><p>- Dropout<br> - Layer normalization<br> - Weight decay<br> - Early stopping</p></td>
<td><p>- Larger model size (more layers/units)<br> - Train longer</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Autoencoders</strong></p></td>
<td><p>- Regularization<br> - Noise injection in input<br> - Early stopping</p></td>
<td><p>- Increase network size<br> - More layers</p></td>
</tr>
<tr class="row-even"><td><p><strong>Support Vector Regression (SVR)</strong></p></td>
<td><p>- Increase regularization<br> - Use simpler kernel</p></td>
<td><p>- Decrease regularization<br> - Use more complex kernel</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Principal Component Analysis (PCA)</strong></p></td>
<td><p>- Use fewer components</p></td>
<td><p>- Use more components</p></td>
</tr>
<tr class="row-even"><td><p><strong>k-Means</strong></p></td>
<td><p>- Reduce number of clusters</p></td>
<td><p>- Increase number of clusters</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Hidden Markov Models (HMM)</strong></p></td>
<td><p>- Regularization<br> - Limit state transitions</p></td>
<td><p>- Increase number of states<br> - Allow more state transitions</p></td>
</tr>
</tbody>
</table>
<hr class="docutils" />
<p>Note that generative models learn the joint probability distribution <span class="math notranslate nohighlight">\( P(X, Y) \)</span> and then use Bayes’ theorem to compute <span class="math notranslate nohighlight">\( P(Y|X) \)</span>, whereas discriminative models learn the conditional probability distribution <span class="math notranslate nohighlight">\( P(Y|X) \)</span> directly.</p>
<p><strong>Generative Models</strong>:</p>
<ul class="simple">
<li><p>Naive Bayes</p></li>
<li><p>Autoencoders</p></li>
<li><p>Hidden Markov Models (HMM)</p></li>
<li><p>Gaussian Mixture Model (not listed before, but it’s generative)</p></li>
</ul>
<p><strong>Discriminative Models</strong>:</p>
<ul class="simple">
<li><p>Linear Regression</p></li>
<li><p>Decision Trees</p></li>
<li><p>SVM (both classification and regression)</p></li>
<li><p>Neural Networks (including CNN, RNN, LSTM, GRU)</p></li>
<li><p>k-NN</p></li>
<li><p>Logistic Regression</p></li>
<li><p>Boosted Trees (e.g., XGBoost, AdaBoost)</p></li>
<li><p>Random Forest</p></li>
<li><p>Gradient Boosting Machines (GBM)</p></li>
<li><p>Transformers (e.g., BERT, GPT)</p></li>
</ul>
<p><strong>Others (neither strictly generative nor discriminative)</strong>:</p>
<ul class="simple">
<li><p>Principal Component Analysis (PCA) - Dimensionality reduction</p></li>
<li><p>k-Means - Clustering</p></li>
</ul>
</section>
<section id="pac-and-vc">
<h2>PAC and VC<a class="headerlink" href="#pac-and-vc" title="Permalink to this heading">#</a></h2>
<section id="pac">
<h3>PAC<a class="headerlink" href="#pac" title="Permalink to this heading">#</a></h3>
<p>PAC (Probably Approximately Correct) learning is a theoretical framework used to describe and quantify the performance of machine learning models on unknown data.</p>
<p>In PAC learning, we hope the model is correct for most of the new, unseen data, but also allow for a small portion of errors. This is where the terms “Probably” and “Approximately Correct” come from.</p>
<p>This framework provides a way to theoretically guarantee the performance of the learning algorithm under certain conditions for new data.</p>
</section>
<section id="vc">
<h3>VC<a class="headerlink" href="#vc" title="Permalink to this heading">#</a></h3>
<p>当我们说 <span class="math notranslate nohighlight">\( \text{VC}(\text{线}) = 3 \)</span> 时，意思是在2D空间中（也就是平面上），线性分类器（由一条直线表示）的VC（Vapnik-Chervonenkis）维度是3。</p>
<p>进一步解释：</p>
<ol class="arabic simple">
<li><p><strong>分割</strong>: 在VC维度的上下文中，“分割”一组点意味着对于这些点的每一个可能的标记（正或负），都存在我们分类器的某种配置（在这种情况下是一条线），可以根据该标记正确地对这些点进行分类。</p></li>
<li><p><strong>VC维度</strong>: 一个假设类（例如2D中所有可能的线）的VC维度是该类可以分割的点的最大数量。它是该类的容量或复杂性的度量。</p></li>
<li><p><strong>VC(线) = 3</strong>: 这意味着在2D中，线可以分割的点的最大数量是3。你可以在平面上找到3个点的配置，这样对于这些点的每一个可能的标记，都有某条线可以正确地对它们进行分类。但是，对于平面上任何4个点的配置，至少有一种标记方式，没有线可以正确地对所有四个点进行分类。</p></li>
</ol>
<p>为了进一步澄清，虽然一条线可以分开平面上的任何三个点，但它不能处理任何四个点的所有可能的标记。因此，2D中所有线的集合的VC维度是3。</p>
</section>
<section id="vc-and-pac">
<h3>VC and PAC<a class="headerlink" href="#vc-and-pac" title="Permalink to this heading">#</a></h3>
<p>VC维度与无穷多的数据点相关，因为它度量了一个假设类可以分割的点的最大数量，而不考虑这些点的具体数量。换句话说，VC维度提供了对一个模型或假设类复杂性的上界，而不是对特定数据集的拟合。</p>
<p>在PAC（Probably Approximately Correct，大概近似正确）学习理论中，VC维度是一个关键概念，因为它允许我们在有限的样本上为模型的泛化性能提供保证。PAC学习的主要目标是确定在给定的置信度和精度下，训练一个假设类需要多少样本。VC维度为这个问题提供了一个答案。具体来说，高的VC维度意味着模型可能更复杂，可能需要更多的数据来进行有效的训练，而低的VC维度意味着模型可能较为简单。</p>
<p>因此，VC维度可以被看作是PAC学习理论的一个扩展，它为我们提供了一个工具来度量和控制模型的复杂性，从而确保在未见数据上的良好性能。</p>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/vc5.png"><img alt="vc" class="bg-primary mb-1 align-center" src="_images/vc5.png" style="width: 800px;" /></a>
<p>VC(F) of a rectangle in 2D = 4</p>
</section>
</section>
<section id="linearity">
<h2>Linearity<a class="headerlink" href="#linearity" title="Permalink to this heading">#</a></h2>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Aspect</p></th>
<th class="head"><p>Linearly Separable Data</p></th>
<th class="head"><p>Non-Linearly Separable Data</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Choice of Model</strong></p></td>
<td><p>- Linear models (e.g., Linear SVM, Logistic Regression)</p></td>
<td><p>- Non-linear models (e.g., Kernel SVM, Decision Trees, Neural Networks)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Feature Engineering</strong></p></td>
<td><p>- Minimal transformations required</p></td>
<td><p>- Polynomial features, interaction terms, or domain-specific transformations might be beneficial</p></td>
</tr>
<tr class="row-even"><td><p><strong>Regularization</strong></p></td>
<td><p>- Might require stronger regularization to prevent overfitting due to perfect separation</p></td>
<td><p>- Regularization still important, but the balance might differ</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Model Complexity</strong></p></td>
<td><p>- Simpler models often suffice</p></td>
<td><p>- More complex models may be needed to capture data patterns</p></td>
</tr>
<tr class="row-even"><td><p><strong>Training Time</strong></p></td>
<td><p>- Typically faster due to simpler models</p></td>
<td><p>- Potentially longer, especially with non-linear algorithms</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Interpretability</strong></p></td>
<td><p>- Linear models are usually more interpretable</p></td>
<td><p>- Complex models (e.g., deep neural networks) might be harder to interpret</p></td>
</tr>
<tr class="row-even"><td><p><strong>Validation Strategy</strong></p></td>
<td><p>- Standard validation techniques apply</p></td>
<td><p>- Ensuring diverse data in validation sets is crucial, given data’s complexity</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Risk of Overfitting</strong></p></td>
<td><p>- With perfect separation, there’s a risk of overfitting</p></td>
<td><p>- Risk exists, especially with very flexible models. Techniques like pruning, dropout, or early stopping might be essential</p></td>
</tr>
<tr class="row-even"><td><p><strong>Kernel Methods (for SVM)</strong></p></td>
<td><p>- Linear kernel is often suitable</p></td>
<td><p>- Non-linear kernels (e.g., RBF, polynomial) might be required</p></td>
</tr>
</tbody>
</table>
</section>
<section id="mle">
<h2>MLE<a class="headerlink" href="#mle" title="Permalink to this heading">#</a></h2>
<p><strong>Maximum Likelihood Estimation (MLE)</strong></p>
<ol class="arabic">
<li><p><strong>Definition</strong>:</p>
<ul class="simple">
<li><p>MLE finds the parameter values that make the observed data most probable.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ \theta_{MLE} = \arg\max_\theta P(D|\theta) \]</div>
</li>
<li><p><strong>Likelihood vs. Probability</strong>:</p>
<ul class="simple">
<li><p><strong>Probability</strong>: <span class="math notranslate nohighlight">\( P(D|\theta) \)</span> - Chance of observing data <span class="math notranslate nohighlight">\( D \)</span> given parameters <span class="math notranslate nohighlight">\( \theta \)</span>.</p></li>
<li><p><strong>Likelihood</strong>: <span class="math notranslate nohighlight">\( L(\theta|D) = P(D|\theta) \)</span> - “Probability” of parameters <span class="math notranslate nohighlight">\( \theta \)</span> given observed data <span class="math notranslate nohighlight">\( D \)</span> (not a true probability distribution over <span class="math notranslate nohighlight">\( \theta \)</span>).</p></li>
</ul>
</li>
<li><p><strong>Log-Likelihood</strong>:</p>
<ul class="simple">
<li><p>Often easier to work with sum of logs than product of probabilities.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ l(\theta) = \log L(\theta|D) \]</div>
</li>
<li><p><strong>MLE for Common Distributions</strong>:</p>
<ul class="simple">
<li><p><strong>Bernoulli</strong>: <span class="math notranslate nohighlight">\( \hat{p} = \frac{\text{number of successes}}{\text{number of trials}} \)</span></p></li>
<li><p><strong>Normal</strong>:</p>
<ul>
<li><p>Mean: <span class="math notranslate nohighlight">\( \hat{\mu} = \frac{1}{n}\sum_{i=1}^n x_i \)</span></p></li>
<li><p>Variance: <span class="math notranslate nohighlight">\( \hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^n (x_i - \hat{\mu})^2 \)</span></p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Invariance</strong>: If <span class="math notranslate nohighlight">\( \hat{\theta} \)</span> is MLE of <span class="math notranslate nohighlight">\( \theta \)</span>, then for any function <span class="math notranslate nohighlight">\( g \)</span>, <span class="math notranslate nohighlight">\( g(\hat{\theta}) \)</span> is MLE of <span class="math notranslate nohighlight">\( g(\theta) \)</span>.</p></li>
<li><p><strong>Consistency</strong>: As sample size <span class="math notranslate nohighlight">\( n \to \infty \)</span>, <span class="math notranslate nohighlight">\( \hat{\theta}_{MLE} \)</span> converges to true <span class="math notranslate nohighlight">\( \theta \)</span> (under regularity conditions).</p></li>
<li><p><strong>Asymptotic Normality</strong>: MLEs are often approximately normally distributed for large <span class="math notranslate nohighlight">\( n \)</span>.</p></li>
</ul>
</li>
<li><p><strong>Information Theory</strong>:</p>
<ul class="simple">
<li><p><strong>Fisher Information</strong>: Expected value of second derivative (negative) of the log-likelihood.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ I(\theta) = -E\left[ \frac{\partial^2 \log L(\theta|D)}{\partial \theta^2} \right] \]</div>
</li>
<li><p><strong>Optimization</strong>:</p>
<ul class="simple">
<li><p>MLE often requires optimization techniques:</p>
<ul>
<li><p><strong>Analytical</strong>: Solve using calculus for <span class="math notranslate nohighlight">\( \frac{\partial l(\theta)}{\partial \theta} = 0 \)</span>.</p></li>
<li><p><strong>Numerical</strong>: Gradient descent, Newton-Raphson, etc.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Constraints</strong>:</p>
<ul class="simple">
<li><p><strong>Lagrange Multipliers</strong>: Used when there are constraints on parameters.</p></li>
</ul>
</li>
<li><p><strong>Regularization</strong>:</p>
<ul class="simple">
<li><p>Add penalty terms to the likelihood to prevent overfitting.</p></li>
</ul>
</li>
</ol>
<section id="mle-and-ols-blue">
<h3>MLE and OLS (BLUE)<a class="headerlink" href="#mle-and-ols-blue" title="Permalink to this heading">#</a></h3>
<p>While MLE and BLUE (Best Linear Unbiased Estimator) can coincide under specific circumstances (such as in the linear regression model with normally distributed errors), they can yield different results in other settings or under different assumptions.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Property/Aspect</p></th>
<th class="head"><p>MLE</p></th>
<th class="head"><p>BLUE (e.g., OLS)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Definition</strong></p></td>
<td><p>Maximizes the likelihood of observed data.</p></td>
<td><p>Minimizes the sum of squared residuals.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Estimation Goal</strong></p></td>
<td><p>Parameter that maximizes data likelihood.</p></td>
<td><p>Linear estimator with minimum variance.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Error Distribution (Linear Regression)</strong></p></td>
<td><p>Assumes specific distribution (e.g., normal for linear regression).</p></td>
<td><p>No explicit distribution assumption, but BLUE under Gauss-Markov conditions.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Efficiency</strong></p></td>
<td><p>Asymptotically efficient under certain conditions.</p></td>
<td><p>Best among linear unbiased estimators under Gauss-Markov conditions.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Bias</strong></p></td>
<td><p>Can be biased, especially in finite samples.</p></td>
<td><p>Unbiased under Gauss-Markov assumptions.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Applicability</strong></p></td>
<td><p>Broad (many models beyond linear regression).</p></td>
<td><p>Primarily linear regression.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Endogeneity</strong></p></td>
<td><p>Requires specific methods to address.</p></td>
<td><p>OLS is biased; requires methods like IV.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Regularization</strong></p></td>
<td><p>Can be incorporated, e.g., penalized likelihood.</p></td>
<td><p>Methods like Ridge and Lasso introduce bias for regularization.</p></td>
</tr>
</tbody>
</table>
<ol class="arabic simple">
<li><p><strong>Different Error Distributions</strong>:</p>
<ul class="simple">
<li><p>In the context of the linear regression model, if the errors are not normally distributed, the MLE for the parameters might differ from the OLS estimator (which is BLUE under Gauss-Markov assumptions). For instance, if the errors follow a Laplace distribution, the MLE would lead to a form of robust regression that minimizes the sum of absolute residuals, which differs from the OLS solution.</p></li>
</ul>
</li>
<li><p><strong>Generalized Linear Models</strong>:</p>
<ul class="simple">
<li><p>For generalized linear models (e.g., logistic regression, Poisson regression), the link function and error distribution can differ from the normal distribution. In these cases, the MLE is typically used to estimate the parameters, and it won’t coincide with the BLUE, which is a concept primarily related to linear models.</p></li>
</ul>
</li>
<li><p><strong>Violation of Gauss-Markov Assumptions</strong>:</p>
<ul class="simple">
<li><p>If any of the Gauss-Markov assumptions (e.g., homoscedasticity, no autocorrelation) are violated, then while OLS remains unbiased, it is no longer the Best (in terms of minimum variance) among the linear unbiased estimators. In such cases, Generalized Least Squares (GLS) might be employed, which could differ from the MLE.</p></li>
</ul>
</li>
<li><p><strong>Non-Linear Models</strong>:</p>
<ul class="simple">
<li><p>For models that are inherently non-linear in parameters, the concept of BLUE may not apply directly. However, MLE can be used for parameter estimation. The estimates from non-linear MLE will be different from any linear unbiased estimator.</p></li>
</ul>
</li>
<li><p><strong>Presence of Endogeneity</strong>:</p>
<ul class="simple">
<li><p>If there is endogeneity in the model (i.e., one or more independent variables are correlated with the error term), OLS is no longer unbiased. Instrumental variables (IV) or two-stage least squares (2SLS) might be employed to rectify this. The resulting IV or 2SLS estimator could differ from the MLE, especially if the error terms are not normally distributed.</p></li>
</ul>
</li>
<li><p><strong>Finite Sample Differences</strong>:</p>
<ul class="simple">
<li><p>Even when the OLS estimator (which might be BLUE) and the MLE coincide asymptotically (i.e., as the sample size goes to infinity), they might differ in finite samples, especially under model misspecification or certain distributional assumptions.</p></li>
</ul>
</li>
<li><p><strong>Regularization and Model Complexity</strong>:</p>
<ul class="simple">
<li><p>In modern statistical learning and when dealing with high-dimensional data, regularization techniques (like Lasso or Ridge regression) are often employed. These estimators intentionally introduce bias to reduce variance and avoid overfitting. The resulting regularized estimators differ from both the traditional BLUE and MLE.</p></li>
</ul>
</li>
</ol>
<p>In summary, while MLE and BLUE can coincide in specific scenarios, they are based on different principles and can diverge in various contexts, especially when assumptions are violated or in more complex models.</p>
</section>
<section id="mle-estimation-example">
<h3>MLE estimation example<a class="headerlink" href="#mle-estimation-example" title="Permalink to this heading">#</a></h3>
<p>I apologize for the oversight. Let’s provide a step-by-step derivation for the MLE of the mean and variance of a normal distribution.</p>
<hr class="docutils" />
<p><strong>Derivation of MLE for Normal Distribution Parameters</strong></p>
<p>Given:</p>
<ul class="simple">
<li><p>Data: <span class="math notranslate nohighlight">\( x_1, x_2, \ldots, x_n \)</span></p></li>
<li><p>Normal distribution PDF:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ f(x_i | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(x_i - \mu)^2}{2\sigma^2} \right) 
\]</div>
<p><strong>Step 1: Likelihood Function</strong></p>
<div class="math notranslate nohighlight">
\[ L(\mu, \sigma^2) = \prod_{i=1}^{n} f(x_i | \mu, \sigma^2) 
\]</div>
<p><strong>Step 2: Log-Likelihood Function</strong></p>
<div class="math notranslate nohighlight">
\[ l(\mu, \sigma^2) = \sum_{i=1}^{n} \left[ \ln \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right) - \frac{(x_i - \mu)^2}{2\sigma^2} \right] 
\]</div>
<p><strong>Step 3: Differentiate w.r.t. <span class="math notranslate nohighlight">\( \mu \)</span></strong></p>
<div class="math notranslate nohighlight">
\[ \frac{\partial l}{\partial \mu} = \sum_{i=1}^{n} \frac{x_i - \mu}{\sigma^2} 
\]</div>
<p>Setting this to zero and solving for <span class="math notranslate nohighlight">\( \mu \)</span> gives:</p>
<div class="math notranslate nohighlight">
\[ \hat{\mu}_{MLE} = \bar{x} 
\]</div>
<p><strong>Step 4: Differentiate w.r.t. <span class="math notranslate nohighlight">\( \sigma^2 \)</span></strong></p>
<div class="math notranslate nohighlight">
\[ \frac{\partial l}{\partial \sigma^2} = \sum_{i=1}^{n} \left[ -\frac{1}{2\sigma^2} + \frac{(x_i - \mu)^2}{2\sigma^4} \right] 
\]</div>
<p>Setting this to zero and solving for <span class="math notranslate nohighlight">\( \sigma^2 \)</span> gives:</p>
<div class="math notranslate nohighlight">
\[ \hat{\sigma^2}_{MLE} = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2 
\]</div>
</section>
<section id="mle-and-optimisation">
<h3>MLE and optimisation<a class="headerlink" href="#mle-and-optimisation" title="Permalink to this heading">#</a></h3>
<p>The Maximum Likelihood Estimation (MLE) process for logistic regression aims to find the parameter values that maximize the likelihood of observing the given data.</p>
<ol class="arabic simple">
<li><p><strong>Model Specification</strong>:
For logistic regression, the probability <span class="math notranslate nohighlight">\( p(y_i = 1 | \mathbf{x}_i) \)</span> that the response <span class="math notranslate nohighlight">\( y_i \)</span> equals 1 given predictors <span class="math notranslate nohighlight">\( \mathbf{x}_i \)</span> is modeled as:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
p(y_i = 1 | \mathbf{x}_i) = \frac{\exp(\beta_0 + \beta_1 x_{i1} + \ldots + \beta_k x_{ik})}{1 + \exp(\beta_0 + \beta_1 x_{i1} + \ldots + \beta_k x_{ik})}
\]</div>
<p>where <span class="math notranslate nohighlight">\( \mathbf{x}_i \)</span> is a vector of predictor variables for the <span class="math notranslate nohighlight">\( i \)</span>-th observation and <span class="math notranslate nohighlight">\( \beta_0, \beta_1, \ldots, \beta_k \)</span> are parameters to be estimated.</p>
<ol class="arabic simple" start="2">
<li><p><strong>Likelihood Function</strong>:
For binary logistic regression with outcome <span class="math notranslate nohighlight">\( y_i \)</span> being 0 or 1:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
L(\beta_0, \beta_1, \ldots, \beta_k) = \prod_{i=1}^{n} p(y_i = 1 | \mathbf{x}_i)^{y_i} \times (1 - p(y_i = 1 | \mathbf{x}_i))^{(1-y_i)}
\]</div>
<p>This function gives the joint probability of observing the entire set of outcomes in the sample.</p>
<ol class="arabic simple" start="3">
<li><p><strong>Log-Likelihood</strong>:
Due to the product form of the likelihood function, it’s computationally more convenient to work with the log-likelihood:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
l(\beta_0, \beta_1, \ldots, \beta_k) = \sum_{i=1}^{n} \left[ y_i \ln(p(y_i = 1 | \mathbf{x}_i)) + (1-y_i) \ln(1 - p(y_i = 1 | \mathbf{x}_i)) \right]
\]</div>
<ol class="arabic simple" start="4">
<li><p><strong>Maximize the Log-Likelihood</strong>:
The goal of MLE is to find the parameter values <span class="math notranslate nohighlight">\( \beta_0, \beta_1, \ldots, \beta_k \)</span> that maximize the log-likelihood function. This is typically done using numerical optimization techniques, such as the Newton-Raphson method or gradient ascent.</p></li>
<li><p><strong>Estimates</strong>:
The values of <span class="math notranslate nohighlight">\( \beta_0, \beta_1, \ldots, \beta_k \)</span> that maximize the log-likelihood are the MLEs for the parameters.</p></li>
<li><p><strong>Check Convergence</strong>:
The optimization process is iterative. At each step, the algorithm updates the parameter estimates in a direction that increases the log-likelihood. Convergence is achieved when the change in log-likelihood between iterations is smaller than a predefined threshold.</p></li>
<li><p><strong>Assess Model Fit</strong>:
Once you have the MLEs, you can assess the fit of the logistic regression model using various statistics, such as the deviance, Akaike’s Information Criterion (AIC), or the Hosmer-Lemeshow goodness-of-fit test.</p></li>
</ol>
</section>
</section>
<section id="optimization-algorithms">
<h2>Optimization algorithms<a class="headerlink" href="#optimization-algorithms" title="Permalink to this heading">#</a></h2>
<p>Optimization algorithms aim to find the best solution (or solutions) to a problem from a set of possible solutions. In machine learning and deep learning, the primary goal of an optimization algorithm is to minimize (or maximize) an objective function, typically known as the loss or cost function. By adjusting the model’s parameters, optimization algorithms try to find the parameter values that result in the lowest possible loss for the given data.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Optimization Algorithm</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Gradient Descent (Batch)</strong></p></td>
<td><p>Updates the parameters in the direction of the negative gradient of the entire dataset at each iteration.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Stochastic Gradient Descent (SGD)</strong></p></td>
<td><p>Updates the parameters using only one training example at a time. It can be noisier but often faster than batch gradient descent.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Mini-batch Gradient Descent</strong></p></td>
<td><p>A compromise between batch and stochastic gradient descent: updates parameters using a subset (or “mini-batch”) of the training data.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Momentum</strong></p></td>
<td><p>Uses a moving average of past gradients to accelerate convergence and reduce oscillations.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Nesterov Accelerated Gradient (NAG)</strong></p></td>
<td><p>A variant of momentum that computes the gradient after the momentum update, leading to more accurate parameter updates.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>AdaGrad</strong></p></td>
<td><p>Adjusts the learning rate for each parameter based on the historical squared gradients.</p></td>
</tr>
<tr class="row-even"><td><p><strong>RMSProp</strong></p></td>
<td><p>Modifies AdaGrad to use a moving average of squared gradients, preventing the learning rate from decreasing too rapidly.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Adam</strong></p></td>
<td><p>Combines elements of Momentum and RMSProp. Maintains moving averages of both gradients and squared gradients.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Adadelta</strong></p></td>
<td><p>An extension of AdaGrad that reduces its aggressive, monotonically decreasing learning rate.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>FTRL (Follow-the-Regularized-Leader)</strong></p></td>
<td><p>Especially suited for large-scale and online learning. Often used with L1 regularization for feature selection.</p></td>
</tr>
<tr class="row-even"><td><p><strong>L-BFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno)</strong></p></td>
<td><p>A quasi-Newton method that approximates the second-order derivative (Hessian) to guide the parameter updates. Suitable for smaller datasets.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Conjugate Gradient</strong></p></td>
<td><p>Uses conjugate directions (instead of just the gradient) to avoid re-visiting previously minimized directions. Used for non-linear optimizations.</p></td>
</tr>
</tbody>
</table>
<section id="gradient-descent-algorithm">
<h3><strong>Gradient Descent Algorithm</strong>:<a class="headerlink" href="#gradient-descent-algorithm" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Initialize the parameter vector <span class="math notranslate nohighlight">\( \theta \)</span> randomly or with zeros.</p></li>
<li><p>Repeat for a specified number of iterations or until convergence:</p>
<ol class="arabic simple">
<li><p>Compute the gradient of the average loss over the training set:</p></li>
</ol>
</li>
</ol>
<div class="math notranslate nohighlight">
\[
   \nabla_\theta J(\theta) = \frac{1}{n} \sum_{i=1}^{n} \nabla_\theta l(\theta, x_i, y_i)
   \]</div>
<ol class="arabic simple" start="2">
<li><p>Update the parameter vector:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
   \theta = \theta - \alpha \nabla_\theta J(\theta)
   \]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( J(\theta) \)</span> is the average loss over the training set.</p></li>
<li><p><span class="math notranslate nohighlight">\( \alpha \)</span> is the learning rate, a hyperparameter that determines the step size during each iteration of the gradient descent. A higher value makes the algorithm converge faster but risks overshooting the minimum, while a lower value ensures more accurate convergence but might be slower.</p></li>
</ul>
</section>
<section id="stochastic-gradient-descent-sgd">
<h3><strong>Stochastic Gradient Descent (SGD)</strong>:<a class="headerlink" href="#stochastic-gradient-descent-sgd" title="Permalink to this heading">#</a></h3>
<p>Stochastic Gradient Descent differs from the standard Gradient Descent in the following ways:</p>
<ol class="arabic simple">
<li><p><strong>Random Single Sample</strong>: Instead of calculating the gradient based on the entire training set, SGD randomly selects one example (<span class="math notranslate nohighlight">\( x_i, y_i \)</span>) at a time to compute the gradient.</p></li>
<li><p><strong>Frequent Updates</strong>: Since it uses only one example at a time, the parameter vector <span class="math notranslate nohighlight">\( \theta \)</span> is updated more frequently, leading to much noisier steps.</p></li>
<li><p><strong>Convergence</strong>: The frequent and noisy updates mean that SGD may never settle at the minimum. Instead, it will oscillate around the minimum. To mitigate this, the learning rate <span class="math notranslate nohighlight">\( \alpha \)</span> is often gradually decreased during training (e.g., learning rate annealing).</p></li>
<li><p><strong>Efficiency and Scalability</strong>: SGD can be faster and more scalable than standard gradient descent, especially when the training set is large, because it starts making updates to <span class="math notranslate nohighlight">\( \theta \)</span> immediately.</p></li>
</ol>
<p>In summary, while standard gradient descent computes the average gradient using the entire training set, stochastic gradient descent approximates the gradient using a single, randomly-selected training example. This makes SGD noisier but often faster and more suitable for large datasets.</p>
</section>
</section>
<section id="nn">
<h2>NN<a class="headerlink" href="#nn" title="Permalink to this heading">#</a></h2>
<section id="backpropogation">
<h3>Backpropogation<a class="headerlink" href="#backpropogation" title="Permalink to this heading">#</a></h3>
<section id="rnn-and-bptt">
<h4>RNN and BPTT<a class="headerlink" href="#rnn-and-bptt" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Sequential Data</strong>:</p>
<ul>
<li><p>RNNs process data one step at a time with a maintained hidden state.</p></li>
</ul>
</li>
<li><p><strong>Temporal Dependencies</strong>:</p>
<ul>
<li><p>RNNs capture relationships across sequence steps.</p></li>
</ul>
</li>
<li><p><strong>Backpropagation Through Time (BPTT)</strong>:</p>
<ul>
<li><p>Adjusts weights considering past steps.</p></li>
<li><p>Essential due to the influence of prior inputs on current outputs.</p></li>
</ul>
</li>
</ul>
<p>BPTT ensures RNNs account for the entire sequence when updating weights.</p>
</section>
</section>
<section id="optimisation-algorithm-nn-vs-other">
<h3>Optimisation Algorithm (NN vs Other)<a class="headerlink" href="#optimisation-algorithm-nn-vs-other" title="Permalink to this heading">#</a></h3>
<p>Optimization algorithms in neural networks (NN) and traditional machine learning models serve the same fundamental purpose: minimizing (or maximizing) an objective function, typically the loss or cost function. However, there are differences in the challenges posed by these models, leading to nuances in the optimization techniques used. Let’s explore these differences:</p>
<ol class="arabic simple">
<li><p><strong>Scale of Parameters</strong>:</p>
<ul class="simple">
<li><p><strong>Neural Networks</strong>: NNs, especially deep networks, can have millions to billions of parameters. Optimizing such a large parameter space introduces challenges not typically found in traditional models.</p></li>
<li><p><strong>Traditional ML Models</strong>: These models often have fewer parameters. For instance, linear regression has one parameter for each feature (plus a bias).</p></li>
</ul>
</li>
<li><p><strong>Non-Convexity</strong>:</p>
<ul class="simple">
<li><p><strong>Neural Networks</strong>: The loss surfaces of deep NNs are non-convex, meaning they have many local minima, saddle points, and complex structures. This makes the optimization landscape challenging.</p></li>
<li><p><strong>Traditional ML Models</strong>: Some traditional models (like linear regression with a squared error loss) have convex loss surfaces, ensuring a unique global minimum.</p></li>
</ul>
</li>
<li><p><strong>Stochasticity</strong>:</p>
<ul class="simple">
<li><p><strong>Neural Networks</strong>: Due to their size and complexity, NNs are often trained using stochastic methods (like mini-batch gradient descent) to speed up convergence.</p></li>
<li><p><strong>Traditional ML Models</strong>: While stochastic methods can be used, many traditional algorithms can efficiently process the entire dataset in one iteration.</p></li>
</ul>
</li>
<li><p><strong>Regularization Techniques</strong>:</p>
<ul class="simple">
<li><p><strong>Neural Networks</strong>: NNs introduce unique regularization techniques like dropout, batch normalization, and weight normalization to combat overfitting and aid optimization.</p></li>
<li><p><strong>Traditional ML Models</strong>: Regularization techniques for traditional models often revolve around adding penalty terms to the loss (e.g., L1 and L2 regularization).</p></li>
</ul>
</li>
<li><p><strong>Learning Rate Scheduling</strong>:</p>
<ul class="simple">
<li><p><strong>Neural Networks</strong>: Adaptive learning rate techniques and schedulers (like learning rate annealing or cyclical learning rates) are more commonly employed in NN training to ensure convergence in complex landscapes.</p></li>
<li><p><strong>Traditional ML Models</strong>: While adaptive learning rates can be used, many traditional algorithms converge well with fixed or simpler learning rate strategies.</p></li>
</ul>
</li>
<li><p><strong>Optimization Algorithms</strong>:</p>
<ul class="simple">
<li><p><strong>Neural Networks</strong>: Advanced optimization algorithms like Adam, RMSProp, and Nadam, which combine momentum and adaptive learning rates, are popular in deep learning.</p></li>
<li><p><strong>Traditional ML Models</strong>: Simpler algorithms like gradient descent, conjugate gradient, and L-BFGS are often sufficient for these models.</p></li>
</ul>
</li>
<li><p><strong>Challenge of Vanishing/Exploding Gradients</strong>:</p>
<ul class="simple">
<li><p><strong>Neural Networks</strong>: Deep networks face the issue of vanishing or exploding gradients, which can hinder training. Techniques like gradient clipping and careful weight initialization are used to mitigate this.</p></li>
<li><p><strong>Traditional ML Models</strong>: These issues are less prevalent in traditional models.</p></li>
</ul>
</li>
<li><p><strong>Parallelism and Hardware Acceleration</strong>:</p>
<ul class="simple">
<li><p><strong>Neural Networks</strong>: Training large NNs benefits significantly from parallelism and hardware acceleration (e.g., GPUs). Optimization algorithms are sometimes adapted to better leverage these hardware capabilities.</p></li>
<li><p><strong>Traditional ML Models</strong>: While some models can be parallelized or hardware-accelerated, the gains are often less pronounced than in deep learning.</p></li>
</ul>
</li>
</ol>
<p>In summary, while the core principles of optimization remain consistent across neural networks and traditional machine learning models, the scale, complexity, and challenges posed by deep learning have led to the development and adaptation of various optimization strategies specific to neural networks.</p>
</section>
<section id="lstm-and-rnn">
<h3>LSTM and RNN<a class="headerlink" href="#lstm-and-rnn" title="Permalink to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Feature/Aspect</p></th>
<th class="head"><p>RNN</p></th>
<th class="head"><p>LSTM</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Gradient Issues</strong></p></td>
<td><p>Prone to vanishing/exploding gradient problems.</p></td>
<td><p>Designed to mitigate the vanishing gradient problem.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Gating Mechanisms</strong></p></td>
<td><p>None</p></td>
<td><p>Uses input, forget, and output gates to regulate information flow.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Memory</strong></p></td>
<td><p>Only has a hidden state.</p></td>
<td><p>Has both a hidden state and a cell state, allowing for longer-term memory.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Complexity</strong></p></td>
<td><p>Simpler, fewer parameters.</p></td>
<td><p>More complex with more parameters, but this leads to better performance on many tasks.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Performance on Sequences</strong></p></td>
<td><p>Struggles with long-term dependencies.</p></td>
<td><p>Excels in capturing long-term dependencies in data.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Flexibility</strong></p></td>
<td><p>Basic structure.</p></td>
<td><p>Variants like Bi-directional LSTMs and Peephole LSTMs offer enhanced capabilities.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Training Stability</strong></p></td>
<td><p>Harder to train on long sequences.</p></td>
<td><p>More stable and consistent training, especially on tasks with long sequences.</p></td>
</tr>
</tbody>
</table>
<p>This table offers a condensed view of the main differences and improvements of LSTMs over traditional RNNs.</p>
</section>
</section>
<section id="svm">
<h2>SVM<a class="headerlink" href="#svm" title="Permalink to this heading">#</a></h2>
<section id="lamda-and-c">
<h3>lamda and C<a class="headerlink" href="#lamda-and-c" title="Permalink to this heading">#</a></h3>
<p>In the context of a soft-margin SVM, <span class="math notranslate nohighlight">\( \lambda \)</span> (often denoted as <span class="math notranslate nohighlight">\( \alpha \)</span> in many textbooks) and <span class="math notranslate nohighlight">\( E \)</span> (often referred to as <span class="math notranslate nohighlight">\( \xi \)</span> or slack variables) have specific interpretations:</p>
<ol class="arabic simple">
<li><p><strong>Lagrange Multipliers (<span class="math notranslate nohighlight">\( \lambda \)</span> or <span class="math notranslate nohighlight">\( \alpha \)</span>)</strong>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( \lambda = 0 \)</span>: The training example is correctly classified and lies outside the margin. It doesn’t influence the decision boundary.</p></li>
<li><p><span class="math notranslate nohighlight">\( 0 &lt; \lambda &lt; C \)</span>: The training example lies on the margin’s boundary and is correctly classified. It is a support vector.</p></li>
<li><p><span class="math notranslate nohighlight">\( \lambda = C \)</span>: The training example is wrongly classified, despite its position to the boundary.</p></li>
<li><p><span class="math notranslate nohighlight">\( \lambda &gt; C \)</span>: impossible</p></li>
</ul>
</li>
<li><p><strong>Slack Variables (<span class="math notranslate nohighlight">\( E \)</span> or <span class="math notranslate nohighlight">\( \xi \)</span>)</strong>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( E = 0 \)</span>: The training example is correctly classified and lies on the correct side of the margin.</p></li>
<li><p><span class="math notranslate nohighlight">\( 0 &lt; E &lt; 1 \)</span>: The training example is correctly classified but lies inside the margin.</p></li>
<li><p><span class="math notranslate nohighlight">\( E = 1 \)</span>: The training example lies exactly on the decision boundary.</p></li>
<li><p><span class="math notranslate nohighlight">\( 1 &lt; E &lt; 2 \)</span>: The training example is misclassified but lies within the margin.</p></li>
<li><p><span class="math notranslate nohighlight">\( E &gt; 2 \)</span>: The training example is misclassified and lies outside the margin on the wrong side.</p></li>
</ul>
</li>
</ol>
<p>So, for the points A, B, C, and D, you’d use the criteria listed above to determine the values of <span class="math notranslate nohighlight">\( \lambda \)</span> and <span class="math notranslate nohighlight">\( E \)</span> based on their positions relative to the decision boundary and margin. The exact values would depend on the specific locations of these points in relation to the SVM’s decision boundary and margin.</p>
</section>
<section id="kernel-proof">
<h3>Kernel Proof<a class="headerlink" href="#kernel-proof" title="Permalink to this heading">#</a></h3>
<p><strong>Mercer’s Theorem</strong>:
Mercer’s theorem provides a criterion to determine if a given function can be used as a kernel.</p>
<p>For a function <span class="math notranslate nohighlight">\( K \)</span> to be a valid kernel:</p>
<ol class="arabic simple">
<li><p>It must take two inputs from the input space and produce a scalar.</p></li>
<li><p>The resulting matrix, formed by evaluating the kernel on every pair of data points from a dataset, must be positive-semidefinite for any choice of dataset.</p></li>
</ol>
<p>The steps you mentioned can be interpreted as follows:</p>
<ol class="arabic simple">
<li><p><strong>Consider a Finite Sequence of Objects</strong>:</p>
<ul class="simple">
<li><p>Suppose you have a finite set of data points <span class="math notranslate nohighlight">\(\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\)</span>.</p></li>
</ul>
</li>
<li><p><strong>Construct the Kernel Matrix</strong>:</p>
<ul class="simple">
<li><p>For every pair of points in this dataset, compute the kernel function’s value, resulting in an <span class="math notranslate nohighlight">\( n \times n \)</span> matrix <span class="math notranslate nohighlight">\( K \)</span> where each entry <span class="math notranslate nohighlight">\( K_{ij} \)</span> is computed as <span class="math notranslate nohighlight">\( K(\mathbf{x}_i, \mathbf{x}_j) \)</span>.</p></li>
</ul>
</li>
<li><p><strong>Positive-Semidefinite Criterion</strong>:</p>
<ul class="simple">
<li><p>The function <span class="math notranslate nohighlight">\( K \)</span> is a valid kernel if and only if the matrix <span class="math notranslate nohighlight">\( K \)</span> is positive-semidefinite for every possible choice of dataset <span class="math notranslate nohighlight">\(\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n\)</span>.</p></li>
</ul>
</li>
</ol>
<section id="example-with-mermer-s">
<h4>Example with Mermer’s<a class="headerlink" href="#example-with-mermer-s" title="Permalink to this heading">#</a></h4>
<p>We’ll use Mercer’s theorem to verify if the polynomial kernel is a valid kernel.</p>
<p><strong>Polynomial Kernel</strong>:
Given two vectors <span class="math notranslate nohighlight">\( \mathbf{x} \)</span> and <span class="math notranslate nohighlight">\( \mathbf{y} \)</span>, the polynomial kernel of degree <span class="math notranslate nohighlight">\( d \)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[
K(\mathbf{x}, \mathbf{y}) = (1 + \mathbf{x} \cdot \mathbf{y})^d
\]</div>
<p><strong>Proof</strong>:
To prove that the polynomial kernel is valid using Mercer’s theorem, we need to demonstrate that the kernel matrix is positive-semidefinite for any dataset.</p>
<ol class="arabic simple">
<li><p><strong>Kernel Matrix Construction</strong>:
Given a dataset <span class="math notranslate nohighlight">\( \mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n \)</span>, we construct the <span class="math notranslate nohighlight">\( n \times n \)</span> kernel matrix <span class="math notranslate nohighlight">\( K \)</span> where each entry <span class="math notranslate nohighlight">\( K_{ij} \)</span> is <span class="math notranslate nohighlight">\( (1 + \mathbf{x}_i \cdot \mathbf{x}_j)^d \)</span>.</p></li>
<li><p><strong>Positive-Semidefiniteness</strong>:
A matrix is positive-semidefinite if and only if all of its eigenvalues are non-negative.</p></li>
</ol>
<p>Consider an arbitrary vector <span class="math notranslate nohighlight">\( \mathbf{z} \)</span> with components <span class="math notranslate nohighlight">\( z_1, z_2, \ldots, z_n \)</span>. We want to prove that:</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^{n} \sum_{j=1}^{n} z_i K_{ij} z_j \geq 0
\]</div>
<p>Using our kernel definition:</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^{n} \sum_{j=1}^{n} z_i (1 + \mathbf{x}_i \cdot \mathbf{x}_j)^d z_j
\]</div>
<p>This quantity is a polynomial sum of products of dot products. Each term in the expansion will be non-negative because it’s a product of <span class="math notranslate nohighlight">\( d \)</span> terms, each of which is non-negative.</p>
<p>Hence, the polynomial kernel satisfies the positive-semidefiniteness criterion for any dataset.</p>
<ol class="arabic simple" start="3">
<li><p><strong>Conclusion</strong>:
By Mercer’s theorem, the polynomial kernel <span class="math notranslate nohighlight">\( K(\mathbf{x}, \mathbf{y}) = (1 + \mathbf{x} \cdot \mathbf{y})^d \)</span> is a valid kernel.</p></li>
</ol>
<p>Note: This proof provides an intuition for the polynomial kernel’s validity, but a more rigorous proof would delve deeper into the properties of positive-semidefinite matrices and the binomial expansion.</p>
</section>
<section id="sum">
<h4>sum<a class="headerlink" href="#sum" title="Permalink to this heading">#</a></h4>
<p>The provided proofs demonstrate that the sum of two positive semidefinite (psd) kernel functions is also a psd kernel function. Let’s go through the two proofs and provide a clearer understanding of each:</p>
<p><strong>Proof 1: Gram Matrix is psd</strong>
<strong>Statement:</strong>
If <span class="math notranslate nohighlight">\( k_a \)</span> and <span class="math notranslate nohighlight">\( k_b \)</span> are two psd kernels with corresponding Gram matrices <span class="math notranslate nohighlight">\( A \)</span> and <span class="math notranslate nohighlight">\( B \)</span> for any set of points <span class="math notranslate nohighlight">\({x_i}^n_{i=1}\)</span>, then the kernel <span class="math notranslate nohighlight">\( k \)</span> defined by the sum of <span class="math notranslate nohighlight">\( k_a \)</span> and <span class="math notranslate nohighlight">\( k_b \)</span> is also a psd kernel.</p>
<p><strong>Proof:</strong>
Given any vector <span class="math notranslate nohighlight">\( \alpha \in \mathbb{R}^n \)</span>, the quadratic form of the Gram matrix for <span class="math notranslate nohighlight">\( k \)</span> is:</p>
<div class="math notranslate nohighlight">
\[ \alpha^T(A + B)\alpha = \alpha^T A \alpha + \alpha^T B \alpha \]</div>
<p>Since both <span class="math notranslate nohighlight">\( A \)</span> and <span class="math notranslate nohighlight">\( B \)</span> are psd, their quadratic forms are non-negative:</p>
<div class="math notranslate nohighlight">
\[ \alpha^T A \alpha \geq 0 \]</div>
<div class="math notranslate nohighlight">
\[ \alpha^T B \alpha \geq 0 \]</div>
<p>Adding the two inequalities:</p>
<div class="math notranslate nohighlight">
\[ \alpha^T A \alpha + \alpha^T B \alpha \geq 0 \]</div>
<p>This means that the Gram matrix for <span class="math notranslate nohighlight">\( k \)</span> is also psd. Therefore, <span class="math notranslate nohighlight">\( k \)</span> is a psd kernel.</p>
<p><strong>Proof 2: Feature Maps</strong>
<strong>Statement:</strong>
Given two psd kernels <span class="math notranslate nohighlight">\( k_a \)</span> and <span class="math notranslate nohighlight">\( k_b \)</span> with associated Reproducing Kernel Hilbert Spaces (RKHS) <span class="math notranslate nohighlight">\( \mathcal{H}_a \)</span> and <span class="math notranslate nohighlight">\( \mathcal{H}_b \)</span> and feature maps <span class="math notranslate nohighlight">\( \phi_a \)</span> and <span class="math notranslate nohighlight">\( \phi_b \)</span>, the sum of these two kernels can be represented using the direct sum of their RKHS.</p>
<p><strong>Proof:</strong>
Define the RKHS <span class="math notranslate nohighlight">\( \mathcal{H} \)</span> as the direct sum of <span class="math notranslate nohighlight">\( \mathcal{H}_a \)</span> and <span class="math notranslate nohighlight">\( \mathcal{H}_b \)</span>:</p>
<div class="math notranslate nohighlight">
\[ \mathcal{H} = \mathcal{H}_a \oplus \mathcal{H}_b \]</div>
<p>An arbitrary element in <span class="math notranslate nohighlight">\( \mathcal{H} \)</span> is represented as <span class="math notranslate nohighlight">\( f_a \oplus f_b \)</span>.</p>
<p>The inner product in <span class="math notranslate nohighlight">\( \mathcal{H} \)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[ \langle f_a \oplus f_b, f'_a \oplus f'_b \rangle_{\mathcal{H}} = \langle f_a, f'_a \rangle_{\mathcal{H}_a} + \langle f_b, f'_b \rangle_{\mathcal{H}_b} \]</div>
<p>Now, define the feature map for <span class="math notranslate nohighlight">\( k \)</span> as:</p>
<div class="math notranslate nohighlight">
\[ \phi(x) = \phi_a(x_a) \oplus \phi_b(x_b) \]</div>
<p>Using this feature map, we can express <span class="math notranslate nohighlight">\( k \)</span> as:</p>
<div class="math notranslate nohighlight">
\[ k(x, x') = \langle \phi(x), \phi(x') \rangle_{\mathcal{H}} \]</div>
<p>This expands to:</p>
<div class="math notranslate nohighlight">
\[ k(x, x') = \langle \phi_a(x_a) \oplus \phi_b(x_b), \phi_a(x'_a) \oplus \phi_b(x'_b) \rangle_{\mathcal{H}} \]</div>
<div class="math notranslate nohighlight">
\[ = \langle \phi_a(x_a), \phi_a(x'_a) \rangle_{\mathcal{H}_a} + \langle \phi_b(x_b), \phi_b(x'_b) \rangle_{\mathcal{H}_b} \]</div>
<div class="math notranslate nohighlight">
\[ = k_a(x_a, x'_a) + k_b(x_b, x'_b) \]</div>
<p>Thus, <span class="math notranslate nohighlight">\( k \)</span> is also a valid psd kernel.</p>
<hr class="docutils" />
<p>Both of these proofs provide evidence that the sum of two psd kernels is also a psd kernel. The first proof uses properties of the Gram matrix, while the second proof utilizes the properties of the feature maps and RKHS.</p>
</section>
<section id="product">
<h4>product<a class="headerlink" href="#product" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://www.quora.com/How-do-I-formally-proof-the-product-of-two-kernels-is-a-kernel-If-K1-x-x1-and-K2-x-x2-are-both-kernel-function-then-K1-x-x1-K2-x-x2-is-also-a-kernel">How do I formally proof the product of two kernels is a kernel? If K1 (x,x1) and K2 (x,x2) are both kernel function, then K1 (x,x1) K2 (x,x2) is also a kernel?</a></p></li>
</ul>
<p><strong>Proof: Product of Two Kernels</strong></p>
<p><strong>Given</strong>:
Two valid kernel functions <span class="math notranslate nohighlight">\( K_1 \)</span> and <span class="math notranslate nohighlight">\( K_2 \)</span> such that:</p>
<div class="math notranslate nohighlight">
\[ K_1(x, y) = \sum_i \phi^{(1)}_i(x) \phi^{(1)}_i(y) \]</div>
<div class="math notranslate nohighlight">
\[ K_2(x, y) = \sum_j \phi^{(2)}_j(x) \phi^{(2)}_j(y) \]</div>
<p><strong>To Prove</strong>:
The product <span class="math notranslate nohighlight">\( K(x, y) = K_1(x, y) K_2(x, y) \)</span> is also a valid kernel function.</p>
<p><strong>Proof</strong>:</p>
<p>Begin by expressing the product of the two kernels:</p>
<div class="math notranslate nohighlight">
\[ K(x, y) = K_1(x, y) K_2(x, y) \]</div>
<div class="math notranslate nohighlight">
\[ = \left( \sum_i \phi^{(1)}_i(x) \phi^{(1)}_i(y) \right) \left( \sum_j \phi^{(2)}_j(x) \phi^{(2)}_j(y) \right) \]</div>
<div class="math notranslate nohighlight">
\[ = \sum_{i, j} \phi^{(1)}_i(x) \phi^{(2)}_j(x) \phi^{(1)}_i(y) \phi^{(2)}_j(y) \]</div>
<p>Now, define a new set of basis functions as the product of the basis functions from the two original kernels:</p>
<div class="math notranslate nohighlight">
\[ \phi_{i,j}(z) = \phi^{(1)}_i(z) \phi^{(2)}_j(z) \]</div>
<p>With this new definition, the product kernel can be written as:</p>
<div class="math notranslate nohighlight">
\[ K(x, y) = \sum_{i, j} \phi_{i,j}(x) \phi_{i,j}(y) \]</div>
<p>Since the resulting kernel function, <span class="math notranslate nohighlight">\( K(x, y) \)</span>, can be expressed as an inner product of a new set of basis functions, it retains the essential property of a kernel.</p>
<p><strong>Conclusion</strong>:
The product of two valid kernel functions, <span class="math notranslate nohighlight">\( K_1 \)</span> and <span class="math notranslate nohighlight">\( K_2 \)</span>, results in another valid kernel function, <span class="math notranslate nohighlight">\( K \)</span>.</p>
<hr class="docutils" />
<p>This structured proof breaks down the multiplication of two kernels and demonstrates that their product can also be represented as a kernel, maintaining the defining properties of a kernel function.</p>
</section>
<section id="exp">
<h4>exp<a class="headerlink" href="#exp" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/320768/proof-that-exponential-of-a-kernel-is-a-kernel">Proof that exponential of a kernel is a kernel</a></p></li>
</ul>
<p><strong>Proof: Exponential of a Kernel</strong></p>
<p><strong>Given</strong>:
A valid kernel function <span class="math notranslate nohighlight">\( K \)</span>.</p>
<p><strong>To Prove</strong>:
The exponential function of the kernel, <span class="math notranslate nohighlight">\( \exp(K) \)</span>, is also a valid kernel.</p>
<p><strong>Proof</strong>:</p>
<ol class="arabic simple">
<li><p><strong>Taylor Expansion</strong>:</p></li>
</ol>
<p>Using the Taylor expansion of the exponential function centered at 0, we have:</p>
<div class="math notranslate nohighlight">
\[ \exp(K) = 1 + K + \frac{1}{2!} K^2 + \frac{1}{3!} K^3 + \dots \]</div>
<p>This expansion represents the exponential of <span class="math notranslate nohighlight">\( K \)</span> as an infinite series consisting of linear combinations and products of powers of the kernel <span class="math notranslate nohighlight">\( K \)</span>.</p>
<ol class="arabic simple" start="2">
<li><p><strong>Kernel Properties</strong>:</p></li>
</ol>
<p>From known properties of kernels:
- The sum of two valid kernels is a valid kernel: <span class="math notranslate nohighlight">\( K' = \alpha K_1 + \beta K_2 \)</span>.
- The product of two valid kernels is a valid kernel: <span class="math notranslate nohighlight">\( K' = K_1 K_2 \)</span>.</p>
<p>Given the kernel <span class="math notranslate nohighlight">\( K \)</span>, any power of <span class="math notranslate nohighlight">\( K \)</span> (e.g., <span class="math notranslate nohighlight">\( K^2, K^3 \)</span>) is also a valid kernel due to the property of products. Also, any linear combination (as seen in the Taylor expansion) would also be a valid kernel due to the property of sums.</p>
<ol class="arabic simple" start="3">
<li><p><strong>Conclusion</strong>:</p></li>
</ol>
<p>Using the properties of kernel addition and multiplication, every term in the Taylor expansion of <span class="math notranslate nohighlight">\( \exp(K) \)</span> represents a valid kernel. As the sum of valid kernels remains valid, the entire series is a valid kernel.</p>
<p>Thus, the exponential of a kernel, <span class="math notranslate nohighlight">\( \exp(K) \)</span>, is also a valid kernel.</p>
</section>
</section>
<hr class="docutils" />
<section id="general-proof-solutions">
<h3>general proof solutions<a class="headerlink" href="#general-proof-solutions" title="Permalink to this heading">#</a></h3>
<p>To prove that a function <span class="math notranslate nohighlight">\( k \)</span> is a valid kernel, one generally needs to demonstrate that the kernel matrix (or Gram matrix) constructed using <span class="math notranslate nohighlight">\( k \)</span> is positive semi-definite (PSD) for any set of input data points. Here are the general approaches to prove this:</p>
<ol class="arabic simple">
<li><p><strong>Direct Method</strong>:</p>
<ul class="simple">
<li><p>Construct the Gram matrix <span class="math notranslate nohighlight">\( K \)</span> using the kernel function <span class="math notranslate nohighlight">\( k \)</span> for any set of data points.</p></li>
<li><p>Show that for any vector <span class="math notranslate nohighlight">\( \alpha \)</span> of appropriate dimensions, the value of <span class="math notranslate nohighlight">\( \alpha^T K \alpha \)</span> is non-negative. If this is true for all such <span class="math notranslate nohighlight">\( \alpha \)</span>, then <span class="math notranslate nohighlight">\( K \)</span> is PSD, and <span class="math notranslate nohighlight">\( k \)</span> is a valid kernel.</p></li>
</ul>
</li>
<li><p><strong>Using Kernel Properties</strong>:</p>
<ul class="simple">
<li><p><strong>Closure Properties</strong>: Kernels have several closure properties. For instance, if <span class="math notranslate nohighlight">\( k_1 \)</span> and <span class="math notranslate nohighlight">\( k_2 \)</span> are kernels, then the following are also kernels:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\( c \cdot k_1 \)</span> for <span class="math notranslate nohighlight">\( c &gt; 0 \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( k_1 + k_2 \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( k_1 \times k_2 \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( f(x) \cdot k_1(x, y) \cdot f(y) \)</span> for any function <span class="math notranslate nohighlight">\( f \)</span></p></li>
</ul>
</li>
<li><p>Using these properties, one can construct new kernels from known kernels.</p></li>
</ul>
</li>
<li><p><strong>Mercer’s Theorem</strong>:</p>
<ul class="simple">
<li><p>Mercer’s theorem provides conditions under which a function can be expressed as an inner product in some (possibly infinite-dimensional) feature space, and therefore is a kernel. If a function satisfies Mercer’s conditions (related to non-negative integrals over the product of the function with test functions), it is a valid kernel.</p></li>
</ul>
</li>
<li><p><strong>Feature Map Representation</strong>:</p>
<ul class="simple">
<li><p>Demonstrate that there exists a feature map <span class="math notranslate nohighlight">\( \phi \)</span> such that <span class="math notranslate nohighlight">\( k(x, y) = \langle \phi(x), \phi(y) \rangle \)</span>, where <span class="math notranslate nohighlight">\( \langle \cdot, \cdot \rangle \)</span> denotes the inner product. If you can explicitly find or describe such a feature map, then <span class="math notranslate nohighlight">\( k \)</span> is a kernel.</p></li>
</ul>
</li>
<li><p><strong>Using Existing Kernels</strong>:</p>
<ul class="simple">
<li><p>Sometimes it’s easier to derive new kernels based on known kernels. If you can express a function in terms of operations and compositions that preserve the kernel property, then the function is a valid kernel.</p></li>
</ul>
</li>
<li><p><strong>Eigenvalues</strong>:</p>
<ul class="simple">
<li><p>Another way to prove a matrix is PSD is by showing all its eigenvalues are non-negative. However, computing eigenvalues might not always be feasible, especially for infinite-dimensional spaces.</p></li>
</ul>
</li>
</ol>
</section>
<section id="unconventional-data">
<h3>Unconventional Data<a class="headerlink" href="#unconventional-data" title="Permalink to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Data Structure</p></th>
<th class="head"><p>Kernel Type</p></th>
<th class="head"><p>Application Example</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Strings</p></td>
<td><p>String Kernels</p></td>
<td><p>DNA or protein sequences</p></td>
<td><p>Compares variable-length strings based on patterns, subsequences, etc.</p></td>
</tr>
<tr class="row-odd"><td><p>Graphs</p></td>
<td><p>Graph Kernels</p></td>
<td><p>Cheminformatics, social network analysis</p></td>
<td><p>Measures similarity based on shared subgraphs, paths, or other graph features.</p></td>
</tr>
<tr class="row-even"><td><p>Sets</p></td>
<td><p>Set Kernels</p></td>
<td><p>“Bag of words” for text data</p></td>
<td><p>Computes similarity between sets based on overlap, shared items, etc.</p></td>
</tr>
<tr class="row-odd"><td><p>Images</p></td>
<td><p>Image Kernels</p></td>
<td><p>Computer vision tasks</p></td>
<td><p>Compares images based on shared visual patterns, color histograms, texture, etc.</p></td>
</tr>
<tr class="row-even"><td><p>Trees</p></td>
<td><p>Tree Kernels</p></td>
<td><p>Natural language processing (sentence parsing)</p></td>
<td><p>Computes similarity between trees (like parse trees) based on shared subtrees or structures.</p></td>
</tr>
</tbody>
</table>
<p><strong>Note on Validity</strong>:</p>
<ul class="simple">
<li><p>A function is a valid kernel if the Gram matrix it induces is positive-semidefinite for any dataset, ensuring it corresponds to a dot product in some feature space.</p></li>
</ul>
</section>
<section id="popular-kernels">
<h3>Popular Kernels<a class="headerlink" href="#popular-kernels" title="Permalink to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Kernel Type</p></th>
<th class="head"><p>Formula</p></th>
<th class="head"><p>Properties</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Linear Kernel</strong></p></td>
<td><p><span class="math notranslate nohighlight">\( K(\mathbf{x}, \mathbf{y}) = \mathbf{x} \cdot \mathbf{y} \)</span></p></td>
<td><p>- Equivalent to standard dot product in input space.<br>- No mapping to higher-dimensional space.<br>- Suitable for linearly separable data.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Polynomial Kernel</strong></p></td>
<td><p><span class="math notranslate nohighlight">\( K(\mathbf{x}, \mathbf{y}) = (c + \mathbf{x} \cdot \mathbf{y})^d \)</span></p></td>
<td><p>- Maps data to polynomial feature space.<br>- Parameter <span class="math notranslate nohighlight">\( d \)</span> controls complexity.<br>- Suitable for polynomial relationships.</p></td>
</tr>
<tr class="row-even"><td><p><strong>RBF/Gaussian Kernel</strong></p></td>
<td><p><span class="math notranslate nohighlight">\( K(\mathbf{x}, \mathbf{y}) = \exp\left(-\frac{|\mathbf{x} - \mathbf{y}|^2}{2\sigma^2}\right) \)</span></p></td>
<td><p>- Maps data to an infinite-dimensional space.<br>- Flexible; can model complex, non-linear relationships.<br>- Parameter <span class="math notranslate nohighlight">\( \sigma \)</span> controls flexibility.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Sigmoid Kernel</strong></p></td>
<td><p><span class="math notranslate nohighlight">\( K(\mathbf{x}, \mathbf{y}) = \tanh(k \mathbf{x} \cdot \mathbf{y} + c) \)</span></p></td>
<td><p>- Used in neural networks.<br>- Can produce non-positive semidefinite matrices.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Laplacian Kernel</strong></p></td>
<td><p><span class="math notranslate nohighlight">\( K(\mathbf{x}, \mathbf{y}) = \exp\left(-\frac{|\mathbf{x} - \mathbf{y}|_1}{\sigma}\right) \)</span></p></td>
<td><p>- Similar to RBF but uses <span class="math notranslate nohighlight">\( L_1 \)</span> norm.<br>- Alternative to RBF in some applications.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>ANOVA Kernel</strong></p></td>
<td><p>Customized for regression problems</p></td>
<td><p>- Suitable for data with multiplicative feature combinations.</p></td>
</tr>
</tbody>
</table>
<p><strong>Key Takeaways</strong>:</p>
<ul class="simple">
<li><p>The choice of kernel significantly impacts machine learning algorithm performance, especially in SVMs.</p></li>
<li><p>Some kernels have parameters that require tuning to optimize performance.</p></li>
<li><p>Ensure the kernel matrix is positive-semidefinite for valid kernel functions.</p></li>
</ul>
</section>
</section>
<section id="cnn">
<h2>CNN<a class="headerlink" href="#cnn" title="Permalink to this heading">#</a></h2>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/cnn3.png"><img alt="cnn" class="bg-primary mb-1 align-center" src="_images/cnn3.png" style="width: 800px;" /></a>
<section id="cnn-and-vi">
<h3>CNN and VI<a class="headerlink" href="#cnn-and-vi" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Convolutional Layers</strong>:</p>
<ul>
<li><p>Use filters with shared weights.</p></li>
<li><p>Detect features anywhere in the image, ensuring consistent feature recognition regardless of position.</p></li>
</ul>
</li>
<li><p><strong>Pooling Layers</strong>:</p>
<ul>
<li><p>Down-sample feature maps (e.g., max-pooling).</p></li>
<li><p>Reduce sensitivity to exact feature locations, adding another layer of spatial invariance.</p></li>
</ul>
</li>
</ul>
<p>Together, these components enable CNNs to achieve translation-invariant classifications by recognizing and classifying image content regardless of its spatial position.</p>
</section>
</section>
<section id="generative-vs-discriminative">
<h2>Generative vs Discriminative<a class="headerlink" href="#generative-vs-discriminative" title="Permalink to this heading">#</a></h2>
<p>Of course, I can help clarify the difference between generative and discriminative models.</p>
<p>Generative models attempt to model how the data is generated. They capture the joint probability distribution <span class="math notranslate nohighlight">\( P(X, Y) \)</span>, where <span class="math notranslate nohighlight">\( X \)</span> is the feature and <span class="math notranslate nohighlight">\( Y \)</span> is the label or class. Using this joint distribution, they can compute the conditional probability <span class="math notranslate nohighlight">\( P(Y|X) \)</span> for prediction.</p>
<p>Discriminative models focus on distinguishing between classes. They model the boundary between classes and learn the conditional probability <span class="math notranslate nohighlight">\( P(Y|X) \)</span> directly without worrying about how the data is generated.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Criteria</p></th>
<th class="head"><p>Generative Models</p></th>
<th class="head"><p>Discriminative Models</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Description</strong></p></td>
<td><p>Model how the data is generated.</p></td>
<td><p>Model the boundary between classes.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>What They Learn</strong></p></td>
<td><p>Distribution of each class.</p></td>
<td><p>Boundary between classes.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Examples</strong></p></td>
<td><p>Gaussian Mixture Models, Naïve Bayes, Hidden Markov Models.</p></td>
<td><p>Logistic Regression, SVM, Random Forests, Neural Networks.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Advantages</strong></p></td>
<td><p>Can generate new data points. More robust with limited data.</p></td>
<td><p>Often more accurate in classification with ample data.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Drawbacks</strong></p></td>
<td><p>Might be less accurate in classification tasks.</p></td>
<td><p>Cannot generate new data points.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Analogy</strong></p></td>
<td><p>Studying individual apples and oranges.</p></td>
<td><p>Looking directly at differences between apples and oranges.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="autoencoder">
<h2>Autoencoder<a class="headerlink" href="#autoencoder" title="Permalink to this heading">#</a></h2>
<p><strong>Autoencoders</strong></p>
<ul class="simple">
<li><p><strong>Purpose</strong>: Unsupervised learning, initialization, efficient coding, and data compression.</p></li>
<li><p><strong>Idea</strong>: Train a neural network to reproduce its input, i.e., model <span class="math notranslate nohighlight">\( p(x|x) \)</span>.</p></li>
</ul>
<p><strong>Topology</strong>:</p>
<ul class="simple">
<li><p><strong>Input</strong> and <strong>output</strong> are the same.</p></li>
<li><p><strong>Bottleneck layer</strong>: Thinner than input, leading to data compression.</p></li>
<li><p>Variations: Introduce noise to input, regularize to make the bottleneck layer sparse or to contract inputs.</p></li>
</ul>
<p><strong>Bottleneck</strong>:</p>
<ul class="simple">
<li><p>If the network can restore the original signal effectively, the data structure can be described by a lower-dimensional representation in the bottleneck.</p></li>
</ul>
<p><strong>Under-/Over-completeness</strong>:</p>
<ul class="simple">
<li><p><strong>Undercomplete</strong>: Thinner bottleneck forces the model to generalize.</p></li>
<li><p><strong>Overcomplete</strong>: Wider bottleneck can simply copy input to output. However, trivial codes can still be learned.</p></li>
</ul>
<p><strong>Uses</strong>:</p>
<ul class="simple">
<li><p>Compression, dimensionality reduction, unsupervised pre-training, and discovering latent feature space.</p></li>
<li><p>Achieves non-linear transformation.</p></li>
<li><p>Related to PCA but provides non-linear dimensionality reduction.</p></li>
</ul>
<p><strong>PCA vs. Autoencoding</strong>:</p>
<ul class="simple">
<li><p>Using linear activations with one hidden layer makes the setup similar to PCA.</p></li>
<li><p>PCA finds orthonormal basis; Neural network might find a different solution.</p></li>
</ul>
<p><strong>Applications of Autoencoders</strong>:</p>
<ul class="simple">
<li><p>Data visualization &amp; clustering.</p></li>
<li><p>Feature representation for off-the-shelf ML methods.</p></li>
<li><p>Pre-training deep models: Initialize weights with encoder parameters. In some fields, replaced with supervised pre-training on large datasets.</p></li>
</ul>
</section>
<section id="map">
<h2>MAP<a class="headerlink" href="#map" title="Permalink to this heading">#</a></h2>
<section id="difference-between-map-and-full-bayesian-inference">
<h3><strong>Difference between MAP and Full Bayesian Inference</strong>:<a class="headerlink" href="#difference-between-map-and-full-bayesian-inference" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Maximum a Posteriori (MAP)</strong>:</p>
<ul>
<li><p>MAP estimation provides a point estimate of a model parameter. Specifically, it estimates the mode of the posterior distribution.</p></li>
<li><p>It is formulated as:</p></li>
</ul>
</li>
</ul>
<div class="math notranslate nohighlight">
\[
    \theta_{\text{MAP}} = \arg\max_{\theta} P(\theta | \text{data}) = \arg\max_{\theta} P(\text{data} | \theta)P(\theta)
    \]</div>
<ul class="simple">
<li><p>It combines the likelihood <span class="math notranslate nohighlight">\( P(\text{data} | \theta) \)</span> with the prior <span class="math notranslate nohighlight">\( P(\theta) \)</span> but doesn’t fully account for the uncertainty in the parameter’s distribution.</p></li>
<li><p><strong>Full Bayesian Inference</strong>:</p>
<ul>
<li><p>Instead of a point estimate, full Bayesian inference considers the entire posterior distribution of the model parameter.</p></li>
<li><p>Predictions are made by integrating over all possible parameter values, weighted by their posterior probabilities.</p></li>
<li><p>This method captures the inherent uncertainty in parameter estimates.</p></li>
</ul>
</li>
</ul>
<p><strong>Situation where MAP and Full Bayesian Inference produce different predictions</strong>:</p>
<p>Consider a scenario where you’re estimating the bias of a coin based on a series of tosses. Let’s assume you have a bimodal posterior distribution for the bias: one peak (mode) near <span class="math notranslate nohighlight">\( \theta = 0.2 \)</span> and another near <span class="math notranslate nohighlight">\( \theta = 0.8 \)</span>, but the latter peak is broader.</p>
<ul class="simple">
<li><p>Using <strong>MAP</strong>, you’d pick the bias of the coin as the value corresponding to the highest peak, let’s say <span class="math notranslate nohighlight">\( \theta = 0.2 \)</span>.</p></li>
<li><p>With <strong>Full Bayesian Inference</strong>, when making predictions (like the probability of the next toss being heads), you’d average over both modes. Because the broader mode near <span class="math notranslate nohighlight">\( \theta = 0.8 \)</span> has a more substantial portion of the probability mass, the full Bayesian prediction might be closer to that of a coin with bias <span class="math notranslate nohighlight">\( \theta = 0.8 \)</span> than <span class="math notranslate nohighlight">\( \theta = 0.2 \)</span>.</p></li>
</ul>
<p>In this situation, despite the MAP estimate being <span class="math notranslate nohighlight">\( \theta = 0.2 \)</span>, the full Bayesian approach might predict as if the bias is closer to <span class="math notranslate nohighlight">\( \theta = 0.8 \)</span>, showcasing how the two methods can lead to different predictions.</p>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/map.png"><img alt="map" class="bg-primary mb-1 align-center" src="_images/map.png" style="width: 800px;" /></a>
</section>
<section id="map-and-ridge-regression-solution">
<h3>MAP and ridge regression solution.<a class="headerlink" href="#map-and-ridge-regression-solution" title="Permalink to this heading">#</a></h3>
<p>MAP estimate in a Bayesian framework with a normal prior on the coefficients is equivalent to the ridge regression solution.</p>
<hr class="docutils" />
<p><strong>Bayesian Interpretation of Ridge Regression</strong></p>
<p>Given a response vector <span class="math notranslate nohighlight">\( y \)</span> and a design matrix <span class="math notranslate nohighlight">\( X \)</span>, the ordinary least squares (OLS) method aims to find a coefficient vector <span class="math notranslate nohighlight">\( \beta \)</span> that minimizes the residual sum of squares (RSS):</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta} = \underset{\beta}{\text{argmin}} \; (y- X\beta)^T (y - X\beta).
\]</div>
<p>Ridge regression builds upon OLS by adding a penalty term to the RSS, leading to:</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta} = \underset{\beta}{\text{argmin}} \; (y- X\beta)^T (y - X\beta) + \lambda \| \beta\|_2^2,
\]</div>
<p>where <span class="math notranslate nohighlight">\( \lambda \)</span> is a non-negative hyperparameter.</p>
<p>From a Bayesian viewpoint, assuming <span class="math notranslate nohighlight">\( X \)</span> is fixed, OLS presumes the conditional distribution of <span class="math notranslate nohighlight">\( y \)</span> as:</p>
<div class="math notranslate nohighlight">
\[
y \mid X, \beta \sim \mathcal{N}(X\beta, \sigma^2 I),
\]</div>
<p>where <span class="math notranslate nohighlight">\( \sigma \)</span> is a positive constant. While frequentist statistics treats <span class="math notranslate nohighlight">\( \beta \)</span> as an unknown fixed vector, Bayesian statistics introduces a prior distribution on <span class="math notranslate nohighlight">\( \beta \)</span>. Supposing the elements of <span class="math notranslate nohighlight">\( \beta \)</span> are independent normals with equal variance, the prior is:</p>
<div class="math notranslate nohighlight">
\[
\beta \sim \mathcal{N}(0, \tau^2 I).
\]</div>
<p>The posterior distribution of <span class="math notranslate nohighlight">\( \beta \)</span> is then:</p>
<div class="math notranslate nohighlight">
\[
p(\beta \mid y, X) \propto \exp \left[ -\frac{1}{2\sigma^2}(y-X\beta)^T (y - X \beta) - \frac{1}{2\tau^2} \|\beta\|_2^2 \right].
\]</div>
<p>The maximum a posteriori (MAP) estimate, or the mode of this posterior, is equivalent to:</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta} = \underset{\beta}{\text{argmin}} \quad (y-X\beta)^T (y - X \beta) + \frac{\sigma^2}{\tau^2} \|\beta\|_2^2,
\]</div>
<p>which matches the ridge regression estimate when the regularization strength <span class="math notranslate nohighlight">\( \lambda \)</span> is set to <span class="math notranslate nohighlight">\( \frac{\sigma^2}{\tau^2} \)</span>.</p>
<hr class="docutils" />
<p>This summary underlines the connection between ridge regression and Bayesian statistics by highlighting the role of priors and the relationship between the penalty term in ridge regression and the posterior distribution in Bayesian estimation.</p>
</section>
<section id="map-and-mle">
<h3>MAP and MLE<a class="headerlink" href="#map-and-mle" title="Permalink to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Feature</p></th>
<th class="head"><p>MLE</p></th>
<th class="head"><p>MAP</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Definition</p></td>
<td><p>Maximizes the likelihood of the data given the parameter</p></td>
<td><p>Maximizes the posterior distribution of the parameter given the data</p></td>
</tr>
<tr class="row-odd"><td><p>Based On</p></td>
<td><p>Likelihood of the data</p></td>
<td><p>Combination of likelihood of the data and a prior distribution</p></td>
</tr>
<tr class="row-even"><td><p>Incorporates Prior Knowledge?</p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>Formula</p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p>Objective</p></td>
<td><p>Describe data as observed</p></td>
<td><p>Combine prior beliefs with data</p></td>
</tr>
<tr class="row-odd"><td><p>Sensitivity to Sample Size</p></td>
<td><p>Sensitive, especially with small sample sizes</p></td>
<td><p>Can be more robust with informative priors especially with small sample sizes</p></td>
</tr>
<tr class="row-even"><td><p>Asymptotic Behavior</p></td>
<td><p>Converges to the true parameter value with enough data</p></td>
<td><p>Converges to true parameter value with enough data and a non-dogmatic prior</p></td>
</tr>
<tr class="row-odd"><td><p>Use Case</p></td>
<td><p>When prior knowledge is absent or intentionally not used</p></td>
<td><p>When prior knowledge is available and it’s desirable to incorporate it into the estimation</p></td>
</tr>
<tr class="row-even"><td><p>Interpretation</p></td>
<td><p>Frequency-based</p></td>
<td><p>Bayesian</p></td>
</tr>
</tbody>
</table>
<section id="at-which-case-is-map-same-as-mle">
<h4>At which case is MAP same as MLE<a class="headerlink" href="#at-which-case-is-map-same-as-mle" title="Permalink to this heading">#</a></h4>
<p>For MLE:</p>
<div class="math notranslate nohighlight">
\[\theta_{MLE} = \arg\max_\theta \log P(X|\theta)
\]</div>
<p>For MAP:</p>
<div class="math notranslate nohighlight">
\[\theta_{MAP} = \arg\max_\theta \left( \log P(X|\theta) + \log P(\theta) \right)
\]</div>
<p>In summary, the MAP is equivalent to the MLE when the prior is uniform or non-informative.</p>
</section>
</section>
</section>
<hr class="docutils" />
<section id="pgm">
<h2>PGM<a class="headerlink" href="#pgm" title="Permalink to this heading">#</a></h2>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/pgm.png"><img alt="pgm" class="bg-primary mb-1 align-center" src="_images/pgm.png" style="width: 800px;" /></a>
<hr class="docutils" />
<a class="bg-primary mb-1 reference internal image-reference" href="_images/slide1.png"><img alt="slide" class="bg-primary mb-1 align-center" src="_images/slide1.png" style="width: 800px;" /></a>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="resources.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Resources</p>
      </div>
    </a>
    <a class="right-next"
       href="week1.0.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">week1</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bias-and-var">Bias and Var</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-importance-reasons-and-approaches">Regularization: Importance, Reasons, and Approaches</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overfitting-and-underfitting">Overfitting and Underfitting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pac-and-vc">PAC and VC</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pac">PAC</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vc">VC</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vc-and-pac">VC and PAC</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linearity">Linearity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mle">MLE</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-and-ols-blue">MLE and OLS (BLUE)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-estimation-example">MLE estimation example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-and-optimisation">MLE and optimisation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-algorithms">Optimization algorithms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent-algorithm"><strong>Gradient Descent Algorithm</strong>:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-gradient-descent-sgd"><strong>Stochastic Gradient Descent (SGD)</strong>:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nn">NN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backpropogation">Backpropogation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rnn-and-bptt">RNN and BPTT</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimisation-algorithm-nn-vs-other">Optimisation Algorithm (NN vs Other)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-and-rnn">LSTM and RNN</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#svm">SVM</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lamda-and-c">lamda and C</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kernel-proof">Kernel Proof</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-with-mermer-s">Example with Mermer’s</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sum">sum</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#product">product</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#exp">exp</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-proof-solutions">general proof solutions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#unconventional-data">Unconventional Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#popular-kernels">Popular Kernels</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cnn">CNN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cnn-and-vi">CNN and VI</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-vs-discriminative">Generative vs Discriminative</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoencoder">Autoencoder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#map">MAP</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#difference-between-map-and-full-bayesian-inference"><strong>Difference between MAP and Full Bayesian Inference</strong>:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#map-and-ridge-regression-solution">MAP and ridge regression solution.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#map-and-mle">MAP and MLE</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#at-which-case-is-map-same-as-mle">At which case is MAP same as MLE</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pgm">PGM</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>